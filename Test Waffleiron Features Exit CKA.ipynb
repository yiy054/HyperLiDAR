{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a33f8a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch.scatter_reduce for 3D to 2D projection.\n",
      "Using torch.scatter_reduce for 3D to 2D projection.\n"
     ]
    }
   ],
   "source": [
    "from models.waffleiron.segmenter import Segmenter\n",
    "import torch\n",
    "from datasets import LIST_DATASETS, Collate\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "import wandb\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torchhd\n",
    "from torchhd.models import Centroid\n",
    "from torchhd import embeddings\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hd_dim, size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.projection = embeddings.Projection(size, hd_dim)\n",
    "        self.projection.weight = nn.Parameter(torchhd.normalize(self.projection.weight), requires_grad=False) # Binary\n",
    "\n",
    "    def forward(self, x):\n",
    "        sample_hv = self.projection(x)\n",
    "        return torchhd.hard_quantize(sample_hv)\n",
    "\n",
    "class Feature_Extractor:\n",
    "    def __init__(self, input_channels=5, feat_channels=768, depth=48, \n",
    "                 grid_shape=[[256, 256], [256, 32], [256, 32]], nb_class=16, layer_norm=True, \n",
    "                 device=torch.device(\"cpu\"), early_exit = [48], **kwargs):\n",
    "        self.model = Segmenter(\n",
    "            input_channels=input_channels,\n",
    "            feat_channels=feat_channels,\n",
    "            depth=depth,\n",
    "            grid_shape=grid_shape,\n",
    "            nb_class=nb_class, # class for prediction\n",
    "            #drop_path_prob=config[\"waffleiron\"][\"drop_path\"],\n",
    "            layer_norm=layer_norm,\n",
    "            early_exit = early_exit\n",
    "        )\n",
    "\n",
    "        classif = torch.nn.Conv1d(\n",
    "            feat_channels, nb_class, 1 # So it fits 16 = nb_class but classifier is not used\n",
    "        )\n",
    "        torch.nn.init.constant_(classif.bias, 0)\n",
    "        torch.nn.init.constant_(classif.weight, 0)\n",
    "        self.model.classif = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(feat_channels),\n",
    "            classif,\n",
    "        )\n",
    "\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.model.classif.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        def get_optimizer(parameters):\n",
    "            return torch.optim.AdamW(\n",
    "                parameters,\n",
    "                lr=0.001,\n",
    "                weight_decay=0.003,\n",
    "            )\n",
    "\n",
    "        optim = get_optimizer(self.model.parameters())\n",
    "        self.device = device\n",
    "        self.device_string = \"cuda:0\" if (torch.cuda.is_available() and kwargs['args'].device == 'gpu') else \"cpu\"\n",
    "        self.num_classes = nb_class\n",
    "        self.early_exit = early_exit\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def load_pretrained(self, path):\n",
    "        # Load pretrained model\n",
    "        path_to_ckpt = path\n",
    "        checkpoint = torch.load(path_to_ckpt,\n",
    "            map_location=self.device_string)\n",
    "        state_dict = checkpoint[\"net\"]  # Adjust key as needed\n",
    "        new_state_dict = OrderedDict()\n",
    "\n",
    "        for k, v in state_dict.items():\n",
    "            new_key = k.replace(\"module.\", \"\")  # Remove \"module.\" prefix\n",
    "            new_state_dict[new_key] = v\n",
    "\n",
    "        self.model.load_state_dict(new_state_dict)\n",
    "\n",
    "        print(\n",
    "            f\"Checkpoint loaded on {self.device_string}: {path_to_ckpt}\"\n",
    "        )\n",
    "\n",
    "        if self.device_string != 'cpu':\n",
    "            torch.cuda.set_device(self.device_string) # cuda:0\n",
    "            self.model = self.model.cuda(self.device_string) # cuda:0\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        #self.model.waffleiron.crop_model(self.early_exit)\n",
    "\n",
    "    def forward_model(self, it, batch, step_type):\n",
    "\n",
    "        # Checking all of the parameters needed for feature extractor\n",
    "        # Obj: only pass what you need\n",
    "        feat = batch[\"feat\"]\n",
    "        labels = batch[\"labels_orig\"]\n",
    "        cell_ind = batch[\"cell_ind\"]\n",
    "        occupied_cell = batch[\"occupied_cells\"]\n",
    "        neighbors_emb = batch[\"neighbors_emb\"]\n",
    "        if self.device_string != 'cpu':\n",
    "            feat = feat.cuda(0, non_blocking=True)\n",
    "            labels = labels.cuda(0, non_blocking=True)\n",
    "            batch[\"upsample\"] = [\n",
    "                up.cuda(0, non_blocking=True) for up in batch[\"upsample\"]\n",
    "            ]\n",
    "            cell_ind = cell_ind.cuda(0, non_blocking=True)\n",
    "            occupied_cell = occupied_cell.cuda(0, non_blocking=True)\n",
    "            neighbors_emb = neighbors_emb.cuda(0, non_blocking=True)\n",
    "        net_inputs = (feat, cell_ind, occupied_cell, neighbors_emb)\n",
    "\n",
    "        if self.device_string != 'cpu':\n",
    "            with torch.autocast(\"cuda\", enabled=True):\n",
    "                # Logits\n",
    "                with torch.no_grad():\n",
    "                    out = self.model(*net_inputs, step_type)\n",
    "                    encode, tokens, out, exit_layer = out[0], out[1], out[2], out[3]\n",
    "                    pred_label = out.max(1)[1]\n",
    "\n",
    "                    # Only return samples that are not noise\n",
    "                    #torch.cuda.synchronize(device=self.device)\n",
    "                    where = labels != 255\n",
    "                    #torch.cuda.synchronize(device=self.device)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                out = self.model(*net_inputs, step_type)\n",
    "                encode, tokens, out, exit_layer = out[0], out[1], out[2], out[3]\n",
    "                pred_label = out.max(1)[1]\n",
    "\n",
    "                # Only return samples that are not noise\n",
    "                where = labels != 255\n",
    "\n",
    "        return tokens[0,:,where], labels[where], pred_label[0, where], exit_layer\n",
    "\n",
    "    def test(self, loader, total_voxels):        \n",
    "        # Metric\n",
    "        miou = MulticlassJaccardIndex(num_classes=self.num_classes, average=None).to(self.device, non_blocking=True)\n",
    "        final_labels = torch.empty((total_voxels), device=self.device)\n",
    "        final_pred = torch.empty((total_voxels), device=self.device)\n",
    "        \n",
    "        start_idx = 0\n",
    "        for it, batch in tqdm(enumerate(loader), desc=\"SoA testing\"):\n",
    "            features, labels, soa_result = self.forward_model(it, batch)\n",
    "            shape_sample = labels.shape[0]\n",
    "            labels = labels.to(dtype = torch.int64, device = self.device, non_blocking=True)\n",
    "            soa_result = soa_result.to(device=self.device, non_blocking=True)\n",
    "            final_labels[start_idx:start_idx+shape_sample] = labels\n",
    "\n",
    "            final_pred[start_idx:start_idx+shape_sample] = soa_result\n",
    "\n",
    "            start_idx += shape_sample\n",
    "\n",
    "        final_labels = final_labels[:start_idx]\n",
    "        final_pred = final_pred[:start_idx]\n",
    "\n",
    "        print(\"================================\")\n",
    "\n",
    "        print('Pred FE', final_pred, \"\\tShape: \", final_pred.shape)\n",
    "        print('Label', final_labels, \"\\tShape: \", final_labels.shape)\n",
    "        accuracy = miou(final_pred, final_labels)\n",
    "        avg_acc = torch.mean(accuracy)\n",
    "        print(f'accuracy: {accuracy}')\n",
    "        print(f'avg acc: {avg_acc}')\n",
    "\n",
    "        #cm = confusion_matrix(pred_hd, first_label, labels=torch.Tensor(range(0,15)))\n",
    "        #print(\"Confusion matrix \\n\")\n",
    "        #print(cm)\n",
    "\n",
    "        print(\"================================\")\n",
    "\n",
    "class HD_Model:\n",
    "    def __init__(self, in_dim, out_dim, num_classes, path_pretrained, \n",
    "                 device=torch.device(\"cpu\"), **kwargs):\n",
    "\n",
    "        encode = Encoder(out_dim, in_dim)\n",
    "        self.encode = encode.to(device=device, non_blocking=True)\n",
    "\n",
    "        model = Centroid(out_dim, num_classes)\n",
    "        self.model = model.to(device=device, non_blocking=True)\n",
    "        self.device = device\n",
    "        self.feature_extractor = Feature_Extractor(nb_class = num_classes, device=self.device, \n",
    "                                                   early_exit=[int(i) for i in kwargs['args'].layers], \n",
    "                                                   args=kwargs['args'])\n",
    "        self.feature_extractor.load_pretrained(path_pretrained)\n",
    "        self.stop = kwargs['args'].layers\n",
    "        self.point_per_iter = kwargs['args'].number_samples\n",
    "        self.num_classes = num_classes\n",
    "        self.max_samples = kwargs['args'].number_samples\n",
    "        self.kwargs = kwargs\n",
    "        self.compensation = None\n",
    "\n",
    "    def normalize(self, samples):\n",
    "\n",
    "        \"\"\" Normalize with Z-score\"\"\"\n",
    "\n",
    "        mean = torch.mean(samples, dim=0)\n",
    "        std = torch.std(samples, dim=0)\n",
    "\n",
    "        samples = (samples - mean) / (std + 1e-8)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader):\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.num_vox_train = 0\n",
    "        self.num_vox_val = 0\n",
    "\n",
    "        for loader, desc, attr in [(self.train_loader, \"Training loader\", \"num_vox_train\"),\n",
    "                           (self.val_loader, \"Validation loader\", \"num_vox_val\")]:\n",
    "            for batch in tqdm(loader, desc=desc):\n",
    "                labels = batch[\"labels_orig\"]\n",
    "\n",
    "                # Ensure labels are tensors\n",
    "                if isinstance(labels, list):\n",
    "                    labels = torch.stack(labels)  # Convert list of tensors to a single tensor\n",
    "                \n",
    "                # Move to GPU if applicable\n",
    "                if self.device.type == \"cuda\":\n",
    "                    labels = labels.cuda(non_blocking=True)\n",
    "\n",
    "                # Compute the number of valid voxels\n",
    "                setattr(self, attr, getattr(self, attr) + (labels != 255).sum().item())\n",
    "\n",
    "        print(\"Finished loading data loaders\")\n",
    "\n",
    "    def set_compensation(self, inter_weights_path):\n",
    "\n",
    "        \"\"\"Load all the paths for every exit\"\"\"\n",
    "\n",
    "        self.linear_weights = {}\n",
    "\n",
    "        for layer, path in inter_weights_path.items():\n",
    "            self.linear_weights[layer] = nn.Linear(768, 768)\n",
    "            state_dict = torch.load(path)\n",
    "            self.linear_weights[layer].load_state_dict(state_dict)\n",
    "            self.linear_weights[layer] = self.linear_weights[layer].to(self.device)\n",
    "        self.compensation = True\n",
    "    \n",
    "    def sample_to_encode(self, it, batch, step_type=\"train\"):\n",
    "        features, labels, soa_result, exit_layer = self.feature_extractor.forward_model(it, batch, step_type=step_type) # Everything for what hasn't been dropped\n",
    "        features = torch.transpose(features, 0, 1).to(dtype=torch.float32, device = self.device, non_blocking=True)\n",
    "        labels = labels.to(dtype=torch.int64, device = self.device, non_blocking=True)\n",
    "\n",
    "        if self.compensation and exit_layer != 47:\n",
    "            features = self.linear_weights[exit_layer](features)\n",
    "\n",
    "        features = self.normalize(features) # Z1 score seems to work\n",
    "\n",
    "        # HD training\n",
    "        samples_hv = self.encode(features)\n",
    "\n",
    "        return samples_hv, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e37efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdarthiv02\u001b[0m (\u001b[33mdarth-iv-02\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "Loading nuScenes-lidarseg...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "404 lidarseg,\n",
      "Done loading in 0.982 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.2 seconds.\n",
      "======\n",
      "Checkpoint loaded on cuda:0: /root/main/ScaLR/saved_models/ckpt_last_scalr.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loader: 100%|████████████████████████████████████████████████████████████████████| 282/282 [01:17<00:00,  3.64it/s]\n",
      "Validation loader: 100%|████████████████████████████████████████████████████████████████████| 61/61 [00:15<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading data loaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "def parse_dict_args(args_dict):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Define arguments dynamically based on the dictionary keys\n",
    "    for key, value in args_dict.items():\n",
    "        if value is not None:\n",
    "            arg_type = type(value)\n",
    "            parser.add_argument(f'--{key}', type=arg_type, default=value)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Simulate command-line arguments\n",
    "    args_list = [f'--{key}={value}' for key, value in args_dict.items()]\n",
    "    \n",
    "    return parser.parse_args(args_list)\n",
    "\n",
    "og_args = {'confidence':1, 'number_samples': 500, 'add_lr': False, \n",
    "        \"dataset\":'nuscenes', \"wandb_run\":False, 'device':'gpu', 'dim':10000, 'batch_points':20000}\n",
    "\n",
    "args = parse_dict_args(og_args)\n",
    "\n",
    "args.seed = None\n",
    "args.layers = ['24', '36']\n",
    "\n",
    "# Set seed\n",
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(args.seed)\n",
    "\n",
    "DIMENSIONS = args.dim\n",
    "FEAT_SIZE = 768\n",
    "NUM_LEVELS = 8000\n",
    "BATCH_SIZE = 1  # for GPUs with enough memory we can process multiple images at ones\n",
    "\n",
    "wandb.login(key=\"9487c04b8eff0c16cac4e785f2b57c3a475767d3\")\n",
    "\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and args.device == 'gpu') else \"cpu\")\n",
    "print(\"Using {} device\".format(device))\n",
    "device_string = \"cuda:0\" if (torch.cuda.is_available() and args.device == 'gpu') else \"cpu\"\n",
    "\n",
    "# Modify the path for each of the folders\n",
    "\n",
    "if args.dataset == 'nuscenes':\n",
    "    path = '/root/main/dataset/nuscenes'\n",
    "elif args.dataset == 'semantic_kitti':\n",
    "    path = '/root/main/dataset/semantickitti'\n",
    "elif args.dataset == 'tls':\n",
    "    path = '/root/main/dataset/tls'\n",
    "\n",
    "\n",
    "# Get datatset\n",
    "DATASET = LIST_DATASETS.get(args.dataset)\n",
    "\n",
    "##### Process dataset #######\n",
    "\n",
    "if args.dataset == 'nuscenes':\n",
    "\n",
    "    kwargs = {\n",
    "        \"rootdir\": path,\n",
    "        \"input_feat\": [\"intensity\", \"xyz\", \"radius\"],\n",
    "        \"voxel_size\": 0.1,\n",
    "        \"num_neighbors\": 16,\n",
    "        \"dim_proj\": [2, 1, 0],\n",
    "        \"grids_shape\": [[256, 256], [256, 32], [256, 32]],\n",
    "        \"fov_xyz\": [[-64, -64, -8], [64, 64, 8]], # Check here\n",
    "    }\n",
    "\n",
    "    # Train dataset\n",
    "    dataset = DATASET(\n",
    "        phase=\"train\",\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    dataset_train = copy.deepcopy(dataset)\n",
    "    dataset_val = copy.deepcopy(dataset)\n",
    "    dataset_train.init_training()\n",
    "    dataset_val.init_val()\n",
    "\n",
    "    num_classes = 16\n",
    "\n",
    "    path_pretrained = '/root/main/ScaLR/saved_models/ckpt_last_scalr.pth'\n",
    "\n",
    "elif args.dataset == 'semantic_kitti':\n",
    "\n",
    "    kwargs = {\n",
    "        \"rootdir\": path,\n",
    "        \"input_feat\": [\"intensity\", \"xyz\", \"radius\"],\n",
    "        \"voxel_size\": 0.1,\n",
    "        \"num_neighbors\": 16,\n",
    "        \"dim_proj\": [2, 1, 0],\n",
    "        \"grids_shape\": [[256, 256], [256, 32], [256, 32]],\n",
    "        \"fov_xyz\": [[-64, -64, -8], [64, 64, 8]], # Check here\n",
    "    }\n",
    "\n",
    "    dataset_train = DATASET(\n",
    "        phase=\"specific_train\",\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = DATASET(\n",
    "        phase=\"val\",\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    num_classes = 19\n",
    "\n",
    "    path_pretrained = '/root/main/ScaLR/saved_models/ckpt_last_kitti.pth'\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Dataset Not identified\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=1,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=Collate(device=device),\n",
    "    persistent_workers=False,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=1,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=Collate(device=device),\n",
    "    persistent_workers=False,\n",
    ")\n",
    "\n",
    "hd_model = HD_Model(FEAT_SIZE, DIMENSIONS, num_classes, path_pretrained, device=device, args=args)\n",
    "hd_model.set_loaders(train_loader=train_loader, val_loader=val_loader)\n",
    "\n",
    "\n",
    "####### SOA results ##########\n",
    "#print(\"SoA results\")\n",
    "\n",
    "#hd_model.feature_extractor.test(hd_model.val_loader, hd_model.num_vox_val+1000, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee271b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(hd_model):\n",
    "\n",
    "    \"\"\" Initial training pass \"\"\"\n",
    "\n",
    "    print(\"\\nTrain First\\n\")\n",
    "\n",
    "    for it, batch in tqdm(enumerate(hd_model.train_loader), desc=\"Training\"):\n",
    "\n",
    "        samples_hv, labels = hd_model.sample_to_encode(it, batch, step_type=\"train\")\n",
    "\n",
    "        for b in range(0, samples_hv.shape[0], hd_model.point_per_iter):\n",
    "            end = min(b + hd_model.point_per_iter, int(samples_hv.shape[0]))  # Ensure we don't exceed num_voxels[i]\n",
    "\n",
    "        #samples_hv = samples_hv.reshape((1,samples_hv.shape[0]))\n",
    "\n",
    "            hd_model.model.add(samples_hv[b:end], labels[b:end])\n",
    "\n",
    "            #if self.device == torch.device(\"cuda:0\"):\n",
    "            #    torch.cuda.synchronize(device=self.device)\n",
    "        if it == hd_model.max_samples:\n",
    "            break\n",
    "\n",
    "    hd_model.model.weight = nn.Parameter(torchhd.normalize(hd_model.model.weight), requires_grad=False) # Binary\n",
    "\n",
    "    x = input(\"CKA values computed\")\n",
    "\n",
    "    threshold_values = []\n",
    "\n",
    "    ## Get the threshold values\n",
    "    for layer in hd_model.stop:\n",
    "        np_cka = np.array([i.cpu() for i in hd_model.feature_extractor.model.waffleiron.cka_losses[int(layer)]])\n",
    "        mean_cka = np.mean(np_cka)\n",
    "        std_cka = np.std(np_cka)\n",
    "        threshold = mean_cka - std_cka\n",
    "        print(\"Threshold = \", threshold)\n",
    "        hd_model.feature_extractor.model.waffleiron.set_exit_threshold(layer = layer, threshold = threshold)\n",
    "\n",
    "def retrain(hd_model, epochs):\n",
    "\n",
    "    \"\"\" Retrain with misclassified samples (also substract)\"\"\"\n",
    "\n",
    "    for e in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "        #count = 0\n",
    "        #self.scramble = np.random.permutation(len(self.im_idx))\n",
    "        \n",
    "        num_wrong = []\n",
    "\n",
    "        for it, batch in tqdm(enumerate(hd_model.train_loader), desc=f\"Retraining epoch {e}\"):\n",
    "\n",
    "            samples_hv, labels = hd_model.sample_to_encode(it, batch, step_type=\"retrain\")\n",
    "            for b in range(0, samples_hv.shape[0], hd_model.point_per_iter):\n",
    "                end = min(b + hd_model.point_per_iter, int(samples_hv.shape[0]))  # Ensure we don't exceed num_voxels[i]\n",
    "                samples_hv_here = samples_hv[b:end]\n",
    "                labels_here = labels[b:end]\n",
    "                sim = hd_model.model(samples_hv_here, dot=True)\n",
    "                #pred_hd = sim.argmax(1).data\n",
    "                pred_hd = torch.argmax(sim, axis=1)\n",
    "\n",
    "                is_wrong = labels_here != pred_hd\n",
    "                \n",
    "                num_wrong.append(sum(is_wrong))\n",
    "\n",
    "                # cancel update if all predictions were correct\n",
    "                if is_wrong.sum().item() == 0:\n",
    "                    continue\n",
    "\n",
    "                # only update wrongly predicted inputs\n",
    "                samples_hv_here = samples_hv_here[is_wrong]\n",
    "                labels_here = labels_here[is_wrong]\n",
    "                pred_hd = pred_hd[is_wrong]\n",
    "\n",
    "                #count = labels.shape[0]\n",
    "\n",
    "                hd_model.model.weight.index_add_(0, labels_here, samples_hv_here)\n",
    "                hd_model.model.weight.index_add_(0, pred_hd, samples_hv_here, alpha=-1.0)\n",
    "\n",
    "            #torch.cuda.synchronize(device=self.device)\n",
    "\n",
    "            if it == hd_model.max_samples:\n",
    "                break\n",
    "\n",
    "        #print(f\"Misclassified for {it}: \", count)\n",
    "\n",
    "        # If you want to test for each sample\n",
    "        #hd_model.test_hd()\n",
    "    \n",
    "        return num_wrong\n",
    "\n",
    "def test_hd(hd_model, loader='val'):\n",
    "\n",
    "    \"\"\" Testing over all the samples in all the scans given \"\"\"\n",
    "\n",
    "    if loader == 'val':\n",
    "        loader = hd_model.val_loader\n",
    "        num_vox = hd_model.num_vox_val\n",
    "    else:\n",
    "        loader = hd_model.train_loader\n",
    "        num_vox = hd_model.num_vox_train\n",
    "\n",
    "    # Metric\n",
    "    miou = MulticlassJaccardIndex(num_classes=hd_model.num_classes, average=None).to(hd_model.device, non_blocking=True)\n",
    "    final_labels = torch.empty((num_vox+1000), dtype=torch.int64, device=hd_model.device)\n",
    "    final_pred = torch.empty((num_vox+1000), dtype=torch.int64, device=hd_model.device)\n",
    "\n",
    "    start_idx = 0\n",
    "    for it, batch in tqdm(enumerate(loader), desc=\"Validation:\"):\n",
    "\n",
    "        samples_hv, labels = hd_model.sample_to_encode(it, batch, \"Test\") # Only return the features that haven't been dropped\n",
    "\n",
    "        for b in range(0, samples_hv.shape[0], hd_model.point_per_iter):\n",
    "            end = min(b + hd_model.point_per_iter, int(samples_hv.shape[0]))  # Ensure we don't exceed num_voxels[i]\n",
    "            samples_hv_here = samples_hv[b:end]\n",
    "            labels_here = labels[b:end]\n",
    "            #torch.cuda.synchronize(device=self.device)\n",
    "\n",
    "            shape_sample = labels_here.shape[0]\n",
    "\n",
    "            #pred_hd = self.model(samples_hv, dot=True).argmax(1).data\n",
    "            sim = hd_model.model(samples_hv_here, dot=True)\n",
    "            #torch.cuda.synchronize(device=self.device)\n",
    "\n",
    "            pred_hd = torch.argmax(sim, axis=1)\n",
    "            #torch.cuda.synchronize(device=self.device)\n",
    "\n",
    "            #print(\"Labels: \", labels.shape[0])\n",
    "            #print(start_idx, start_idx+shape_sample)\n",
    "            #print(shape_sample)\n",
    "\n",
    "            final_labels[start_idx:start_idx+shape_sample] = labels_here\n",
    "            final_pred[start_idx:start_idx+shape_sample] = pred_hd\n",
    "\n",
    "            start_idx += shape_sample\n",
    "\n",
    "        if it == hd_model.max_samples:\n",
    "            break\n",
    "\n",
    "    final_labels = final_labels[:start_idx]\n",
    "    final_pred = final_pred[:start_idx]\n",
    "\n",
    "    print(\"================================\")\n",
    "\n",
    "    #print('pred_ts', pred_ts)\n",
    "    print('pred_hd', final_pred, \"\\tShape: \", final_pred.shape)\n",
    "    print('label', final_labels, \"\\tShape: \", final_labels.shape)\n",
    "    accuracy = miou(final_pred, final_labels)\n",
    "    avg_acc = torch.mean(accuracy)\n",
    "    print(f'accuracy: {accuracy}')\n",
    "    print(f'avg acc: {avg_acc}')\n",
    "\n",
    "    if args.wandb_run:\n",
    "        log_data = {f\"Training class_{i}_IoU\": c for i, c in enumerate(accuracy)}\n",
    "        log_data[\"Retraining epoch\"] = avg_acc\n",
    "        wandb.log(log_data)\n",
    "\n",
    "    #cm = confusion_matrix(pred_hd, first_label, labels=torch.Tensor(range(0,15)))\n",
    "    #print(\"Confusion matrix \\n\")\n",
    "    #print(cm)\n",
    "\n",
    "    print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d79e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/HyperLiDAR/wandb/run-20250320_070249-nuscenes_training_layers_['24', '36']_norm_dim_10000_OFA_early_exit</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/darth-iv-02/scalr_hd/runs/nuscenes_training_layers_%5B%2724%27%2C%20%2736%27%5D_norm_dim_10000_OFA_early_exit' target=\"_blank\">nuscenes_training_layers_['24', '36']_norm_dim_10000_OFA_early_exit</a></strong> to <a href='https://wandb.ai/darth-iv-02/scalr_hd' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/darth-iv-02/scalr_hd' target=\"_blank\">https://wandb.ai/darth-iv-02/scalr_hd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/darth-iv-02/scalr_hd/runs/nuscenes_training_layers_%5B%2724%27%2C%20%2736%27%5D_norm_dim_10000_OFA_early_exit' target=\"_blank\">https://wandb.ai/darth-iv-02/scalr_hd/runs/nuscenes_training_layers_%5B%2724%27%2C%20%2736%27%5D_norm_dim_10000_OFA_early_exit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Training\n",
      "\n",
      "Train First\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:00, ?it/s]/home/HyperLiDAR/models/waffleiron/helper_projection.py:27: UserWarning: scatter_reduce() is in beta and the API may change at any time. (Triggered internally at  ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:1550.)\n",
      "  residual.scatter_reduce_(\n",
      "/tmp/ipykernel_17965/1220565487.py:36: DeprecationWarning: torchhd.hard_quantize is deprecated, consider using torchhd.normalize instead.\n",
      "  return torchhd.hard_quantize(sample_hv)\n",
      "Training: 282it [03:27,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKA values computed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/root/anaconda3/envs/env/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/root/anaconda3/envs/env/lib/python3.8/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/root/anaconda3/envs/env/lib/python3.8/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/root/anaconda3/envs/env/lib/python3.8/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold =  nan\n",
      "{24: nan}\n",
      "Threshold saved\n",
      "Threshold =  nan\n",
      "{24: nan, 36: nan}\n",
      "Threshold saved\n"
     ]
    }
   ],
   "source": [
    "hd_model.set_compensation({24: 'linear_weights_24_0.75.pth', 36: 'linear_weights_36_ep_0.75.pth'} )\n",
    "\n",
    "if args.wandb_run:\n",
    "    run = wandb.init(\n",
    "        # Set the project where this run will be logged\n",
    "        project=\"scalr_hd\",\n",
    "        # Track hyperparameters and run metadata\n",
    "        config={\n",
    "            \"encoding\": \"Random Projection\",\n",
    "            \"hd_dim\": DIMENSIONS,\n",
    "            \"training_samples\":args.number_samples,\n",
    "        },\n",
    "        id=f\"{args.dataset}_training_layers_{args.layers}_norm_dim_{DIMENSIONS}_OFA_early_exit\",\n",
    "    )\n",
    "\n",
    "####### HD Pipeline ##########\n",
    "\n",
    "print(\"Initial Training\")\n",
    "train(hd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "738087c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:: 0it [00:00, ?it/s]/tmp/ipykernel_17965/1220565487.py:36: DeprecationWarning: torchhd.hard_quantize is deprecated, consider using torchhd.normalize instead.\n",
      "  return torchhd.hard_quantize(sample_hv)\n",
      "Validation:: 61it [00:43,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "pred_hd tensor([15, 15, 15,  ..., 15, 14, 14], device='cuda:0') \tShape:  torch.Size([993322])\n",
      "label tensor([15, 15, 15,  ..., 15, 14, 14], device='cuda:0') \tShape:  torch.Size([993322])\n",
      "accuracy: tensor([0.2416, 0.0032, 0.4758, 0.6114, 0.2283, 0.1887, 0.2656, 0.0569, 0.3964,\n",
      "        0.4261, 0.7135, 0.1548, 0.3634, 0.4264, 0.6573, 0.6660],\n",
      "       device='cuda:0')\n",
      "avg acc: 0.3672163486480713\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "test_hd(hd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee12aa1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                          | 0/1 [00:00<?, ?it/s]\n",
      "Retraining epoch 0: 0it [00:00, ?it/s]\u001b[A/tmp/ipykernel_17965/1220565487.py:36: DeprecationWarning: torchhd.hard_quantize is deprecated, consider using torchhd.normalize instead.\n",
      "  return torchhd.hard_quantize(sample_hv)\n",
      "\n",
      "Retraining epoch 0: 1it [00:01,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 2it [00:02,  1.34s/it]\u001b[A\n",
      "Retraining epoch 0: 3it [00:03,  1.28s/it]\u001b[A\n",
      "Retraining epoch 0: 4it [00:05,  1.33s/it]\u001b[A\n",
      "Retraining epoch 0: 5it [00:06,  1.35s/it]\u001b[A\n",
      "Retraining epoch 0: 6it [00:08,  1.52s/it]\u001b[A\n",
      "Retraining epoch 0: 7it [00:10,  1.49s/it]\u001b[A\n",
      "Retraining epoch 0: 8it [00:11,  1.57s/it]\u001b[A\n",
      "Retraining epoch 0: 9it [00:12,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 10it [00:14,  1.43s/it]\u001b[A\n",
      "Retraining epoch 0: 11it [00:15,  1.37s/it]\u001b[A\n",
      "Retraining epoch 0: 12it [00:16,  1.37s/it]\u001b[A\n",
      "Retraining epoch 0: 13it [00:18,  1.32s/it]\u001b[A\n",
      "Retraining epoch 0: 14it [00:19,  1.26s/it]\u001b[A\n",
      "Retraining epoch 0: 15it [00:20,  1.29s/it]\u001b[A\n",
      "Retraining epoch 0: 16it [00:22,  1.34s/it]\u001b[A\n",
      "Retraining epoch 0: 17it [00:23,  1.35s/it]\u001b[A\n",
      "Retraining epoch 0: 18it [00:24,  1.31s/it]\u001b[A\n",
      "Retraining epoch 0: 19it [00:26,  1.48s/it]\u001b[A\n",
      "Retraining epoch 0: 20it [00:27,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 21it [00:29,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 22it [00:30,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 23it [00:32,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 24it [00:33,  1.46s/it]\u001b[A\n",
      "Retraining epoch 0: 25it [00:35,  1.51s/it]\u001b[A\n",
      "Retraining epoch 0: 26it [00:36,  1.52s/it]\u001b[A\n",
      "Retraining epoch 0: 27it [00:38,  1.49s/it]\u001b[A\n",
      "Retraining epoch 0: 28it [00:39,  1.55s/it]\u001b[A\n",
      "Retraining epoch 0: 29it [00:41,  1.54s/it]\u001b[A\n",
      "Retraining epoch 0: 30it [00:43,  1.58s/it]\u001b[A\n",
      "Retraining epoch 0: 31it [00:44,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 32it [00:45,  1.50s/it]\u001b[A\n",
      "Retraining epoch 0: 33it [00:47,  1.54s/it]\u001b[A\n",
      "Retraining epoch 0: 34it [00:49,  1.55s/it]\u001b[A\n",
      "Retraining epoch 0: 35it [00:50,  1.55s/it]\u001b[A\n",
      "Retraining epoch 0: 36it [00:51,  1.40s/it]\u001b[A\n",
      "Retraining epoch 0: 37it [00:53,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 38it [00:54,  1.47s/it]\u001b[A\n",
      "Retraining epoch 0: 39it [00:56,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 40it [00:57,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 41it [00:58,  1.42s/it]\u001b[A\n",
      "Retraining epoch 0: 42it [01:00,  1.47s/it]\u001b[A\n",
      "Retraining epoch 0: 43it [01:01,  1.46s/it]\u001b[A\n",
      "Retraining epoch 0: 44it [01:03,  1.48s/it]\u001b[A\n",
      "Retraining epoch 0: 45it [01:04,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 46it [01:06,  1.49s/it]\u001b[A\n",
      "Retraining epoch 0: 47it [01:07,  1.47s/it]\u001b[A\n",
      "Retraining epoch 0: 48it [01:08,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 49it [01:10,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 50it [01:11,  1.46s/it]\u001b[A\n",
      "Retraining epoch 0: 51it [01:13,  1.47s/it]\u001b[A\n",
      "Retraining epoch 0: 52it [01:14,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 53it [01:16,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 54it [01:17,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 55it [01:18,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 56it [01:20,  1.42s/it]\u001b[A\n",
      "Retraining epoch 0: 57it [01:21,  1.34s/it]\u001b[A\n",
      "Retraining epoch 0: 58it [01:22,  1.29s/it]\u001b[A\n",
      "Retraining epoch 0: 59it [01:24,  1.48s/it]\u001b[A\n",
      "Retraining epoch 0: 60it [01:26,  1.54s/it]\u001b[A\n",
      "Retraining epoch 0: 61it [01:27,  1.54s/it]\u001b[A\n",
      "Retraining epoch 0: 62it [01:29,  1.53s/it]\u001b[A\n",
      "Retraining epoch 0: 63it [01:30,  1.51s/it]\u001b[A\n",
      "Retraining epoch 0: 64it [01:31,  1.37s/it]\u001b[A\n",
      "Retraining epoch 0: 65it [01:33,  1.42s/it]\u001b[A\n",
      "Retraining epoch 0: 66it [01:34,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 67it [01:36,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 68it [01:37,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 69it [01:38,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 70it [01:40,  1.38s/it]\u001b[A\n",
      "Retraining epoch 0: 71it [01:41,  1.43s/it]\u001b[A\n",
      "Retraining epoch 0: 72it [01:43,  1.48s/it]\u001b[A\n",
      "Retraining epoch 0: 73it [01:44,  1.32s/it]\u001b[A\n",
      "Retraining epoch 0: 74it [01:45,  1.35s/it]\u001b[A\n",
      "Retraining epoch 0: 75it [01:47,  1.35s/it]\u001b[A\n",
      "Retraining epoch 0: 76it [01:48,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 77it [01:49,  1.32s/it]\u001b[A\n",
      "Retraining epoch 0: 78it [01:51,  1.34s/it]\u001b[A\n",
      "Retraining epoch 0: 79it [01:52,  1.43s/it]\u001b[A\n",
      "Retraining epoch 0: 80it [01:54,  1.47s/it]\u001b[A\n",
      "Retraining epoch 0: 81it [01:56,  1.52s/it]\u001b[A\n",
      "Retraining epoch 0: 82it [01:57,  1.52s/it]\u001b[A\n",
      "Retraining epoch 0: 83it [01:59,  1.50s/it]\u001b[A\n",
      "Retraining epoch 0: 84it [02:00,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 85it [02:01,  1.43s/it]\u001b[A\n",
      "Retraining epoch 0: 86it [02:02,  1.35s/it]\u001b[A\n",
      "Retraining epoch 0: 87it [02:04,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 88it [02:05,  1.43s/it]\u001b[A\n",
      "Retraining epoch 0: 89it [02:07,  1.43s/it]\u001b[A\n",
      "Retraining epoch 0: 90it [02:08,  1.47s/it]\u001b[A\n",
      "Retraining epoch 0: 91it [02:10,  1.50s/it]\u001b[A\n",
      "Retraining epoch 0: 92it [02:11,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 93it [02:12,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 94it [02:14,  1.50s/it]\u001b[A\n",
      "Retraining epoch 0: 95it [02:16,  1.55s/it]\u001b[A\n",
      "Retraining epoch 0: 96it [02:18,  1.79s/it]\u001b[A\n",
      "Retraining epoch 0: 97it [02:20,  1.71s/it]\u001b[A\n",
      "Retraining epoch 0: 98it [02:21,  1.65s/it]\u001b[A\n",
      "Retraining epoch 0: 99it [02:22,  1.48s/it]\u001b[A\n",
      "Retraining epoch 0: 100it [02:24,  1.49s/it]\u001b[A\n",
      "Retraining epoch 0: 101it [02:25,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 102it [02:26,  1.33s/it]\u001b[A\n",
      "Retraining epoch 0: 103it [02:27,  1.26s/it]\u001b[A\n",
      "Retraining epoch 0: 104it [02:29,  1.31s/it]\u001b[A\n",
      "Retraining epoch 0: 105it [02:30,  1.35s/it]\u001b[A\n",
      "Retraining epoch 0: 106it [02:32,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 107it [02:33,  1.47s/it]\u001b[A\n",
      "Retraining epoch 0: 108it [02:35,  1.52s/it]\u001b[A\n",
      "Retraining epoch 0: 109it [02:37,  1.51s/it]\u001b[A\n",
      "Retraining epoch 0: 110it [02:38,  1.50s/it]\u001b[A\n",
      "Retraining epoch 0: 111it [02:39,  1.49s/it]\u001b[A\n",
      "Retraining epoch 0: 112it [02:41,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 113it [02:42,  1.47s/it]\u001b[A\n",
      "Retraining epoch 0: 114it [02:44,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 115it [02:45,  1.47s/it]\u001b[A\n",
      "Retraining epoch 0: 116it [02:47,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 117it [02:48,  1.40s/it]\u001b[A\n",
      "Retraining epoch 0: 118it [02:49,  1.42s/it]\u001b[A\n",
      "Retraining epoch 0: 119it [02:51,  1.38s/it]\u001b[A\n",
      "Retraining epoch 0: 120it [02:52,  1.40s/it]\u001b[A\n",
      "Retraining epoch 0: 121it [02:54,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 122it [02:55,  1.37s/it]\u001b[A\n",
      "Retraining epoch 0: 123it [02:56,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 124it [02:58,  1.40s/it]\u001b[A\n",
      "Retraining epoch 0: 125it [02:59,  1.37s/it]\u001b[A\n",
      "Retraining epoch 0: 126it [03:00,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 127it [03:01,  1.29s/it]\u001b[A\n",
      "Retraining epoch 0: 128it [03:03,  1.31s/it]\u001b[A\n",
      "Retraining epoch 0: 129it [03:04,  1.31s/it]\u001b[A\n",
      "Retraining epoch 0: 130it [03:05,  1.30s/it]\u001b[A\n",
      "Retraining epoch 0: 131it [03:07,  1.29s/it]\u001b[A\n",
      "Retraining epoch 0: 132it [03:08,  1.38s/it]\u001b[A\n",
      "Retraining epoch 0: 133it [03:10,  1.38s/it]\u001b[A\n",
      "Retraining epoch 0: 134it [03:11,  1.37s/it]\u001b[A\n",
      "Retraining epoch 0: 135it [03:12,  1.32s/it]\u001b[A\n",
      "Retraining epoch 0: 136it [03:14,  1.33s/it]\u001b[A\n",
      "Retraining epoch 0: 137it [03:15,  1.26s/it]\u001b[A\n",
      "Retraining epoch 0: 138it [03:16,  1.34s/it]\u001b[A\n",
      "Retraining epoch 0: 139it [03:17,  1.33s/it]\u001b[A\n",
      "Retraining epoch 0: 140it [03:19,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 141it [03:20,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 142it [03:22,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 143it [03:23,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 144it [03:25,  1.42s/it]\u001b[A\n",
      "Retraining epoch 0: 145it [03:27,  1.52s/it]\u001b[A\n",
      "Retraining epoch 0: 146it [03:28,  1.54s/it]\u001b[A\n",
      "Retraining epoch 0: 147it [03:30,  1.57s/it]\u001b[A\n",
      "Retraining epoch 0: 148it [03:32,  1.62s/it]\u001b[A\n",
      "Retraining epoch 0: 149it [03:33,  1.69s/it]\u001b[A\n",
      "Retraining epoch 0: 150it [03:35,  1.68s/it]\u001b[A\n",
      "Retraining epoch 0: 151it [03:37,  1.70s/it]\u001b[A\n",
      "Retraining epoch 0: 152it [03:38,  1.58s/it]\u001b[A\n",
      "Retraining epoch 0: 153it [03:40,  1.53s/it]\u001b[A\n",
      "Retraining epoch 0: 154it [03:41,  1.48s/it]\u001b[A\n",
      "Retraining epoch 0: 155it [03:42,  1.47s/it]\u001b[A\n",
      "Retraining epoch 0: 156it [03:44,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 157it [03:45,  1.40s/it]\u001b[A\n",
      "Retraining epoch 0: 158it [03:46,  1.42s/it]\u001b[A\n",
      "Retraining epoch 0: 159it [03:48,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 160it [03:49,  1.38s/it]\u001b[A\n",
      "Retraining epoch 0: 161it [03:50,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 162it [03:52,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 163it [03:54,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 164it [03:55,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 165it [03:56,  1.47s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining epoch 0: 166it [03:58,  1.38s/it]\u001b[A\n",
      "Retraining epoch 0: 167it [03:59,  1.37s/it]\u001b[A\n",
      "Retraining epoch 0: 168it [04:00,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 169it [04:02,  1.35s/it]\u001b[A\n",
      "Retraining epoch 0: 170it [04:03,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 171it [04:05,  1.46s/it]\u001b[A\n",
      "Retraining epoch 0: 172it [04:06,  1.48s/it]\u001b[A\n",
      "Retraining epoch 0: 173it [04:08,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 174it [04:09,  1.54s/it]\u001b[A\n",
      "Retraining epoch 0: 175it [04:11,  1.65s/it]\u001b[A\n",
      "Retraining epoch 0: 176it [04:13,  1.58s/it]\u001b[A\n",
      "Retraining epoch 0: 177it [04:14,  1.52s/it]\u001b[A\n",
      "Retraining epoch 0: 178it [04:16,  1.50s/it]\u001b[A\n",
      "Retraining epoch 0: 179it [04:17,  1.54s/it]\u001b[A\n",
      "Retraining epoch 0: 180it [04:19,  1.60s/it]\u001b[A\n",
      "Retraining epoch 0: 181it [04:21,  1.67s/it]\u001b[A\n",
      "Retraining epoch 0: 182it [04:22,  1.69s/it]\u001b[A\n",
      "Retraining epoch 0: 183it [04:24,  1.71s/it]\u001b[A\n",
      "Retraining epoch 0: 184it [04:26,  1.73s/it]\u001b[A\n",
      "Retraining epoch 0: 185it [04:27,  1.65s/it]\u001b[A\n",
      "Retraining epoch 0: 186it [04:29,  1.67s/it]\u001b[A\n",
      "Retraining epoch 0: 187it [04:31,  1.68s/it]\u001b[A\n",
      "Retraining epoch 0: 188it [04:32,  1.62s/it]\u001b[A\n",
      "Retraining epoch 0: 189it [04:34,  1.71s/it]\u001b[A\n",
      "Retraining epoch 0: 190it [04:36,  1.75s/it]\u001b[A\n",
      "Retraining epoch 0: 191it [04:38,  1.69s/it]\u001b[A\n",
      "Retraining epoch 0: 192it [04:39,  1.66s/it]\u001b[A\n",
      "Retraining epoch 0: 193it [04:41,  1.64s/it]\u001b[A\n",
      "Retraining epoch 0: 194it [04:42,  1.62s/it]\u001b[A\n",
      "Retraining epoch 0: 195it [04:44,  1.63s/it]\u001b[A\n",
      "Retraining epoch 0: 196it [04:46,  1.61s/it]\u001b[A\n",
      "Retraining epoch 0: 197it [04:47,  1.54s/it]\u001b[A\n",
      "Retraining epoch 0: 198it [04:49,  1.56s/it]\u001b[A\n",
      "Retraining epoch 0: 199it [04:50,  1.58s/it]\u001b[A\n",
      "Retraining epoch 0: 200it [04:52,  1.63s/it]\u001b[A\n",
      "Retraining epoch 0: 201it [04:54,  1.61s/it]\u001b[A\n",
      "Retraining epoch 0: 202it [04:55,  1.61s/it]\u001b[A\n",
      "Retraining epoch 0: 203it [04:57,  1.67s/it]\u001b[A\n",
      "Retraining epoch 0: 204it [04:59,  1.65s/it]\u001b[A\n",
      "Retraining epoch 0: 205it [05:00,  1.66s/it]\u001b[A\n",
      "Retraining epoch 0: 206it [05:01,  1.52s/it]\u001b[A\n",
      "Retraining epoch 0: 207it [05:03,  1.53s/it]\u001b[A\n",
      "Retraining epoch 0: 208it [05:05,  1.58s/it]\u001b[A\n",
      "Retraining epoch 0: 209it [05:06,  1.58s/it]\u001b[A\n",
      "Retraining epoch 0: 210it [05:09,  1.92s/it]\u001b[A\n",
      "Retraining epoch 0: 211it [05:11,  1.84s/it]\u001b[A\n",
      "Retraining epoch 0: 212it [05:12,  1.77s/it]\u001b[A\n",
      "Retraining epoch 0: 213it [05:14,  1.76s/it]\u001b[A\n",
      "Retraining epoch 0: 214it [05:16,  1.69s/it]\u001b[A\n",
      "Retraining epoch 0: 215it [05:17,  1.62s/it]\u001b[A\n",
      "Retraining epoch 0: 216it [05:19,  1.61s/it]\u001b[A\n",
      "Retraining epoch 0: 217it [05:20,  1.69s/it]\u001b[A\n",
      "Retraining epoch 0: 218it [05:22,  1.60s/it]\u001b[A\n",
      "Retraining epoch 0: 219it [05:24,  1.70s/it]\u001b[A\n",
      "Retraining epoch 0: 220it [05:25,  1.60s/it]\u001b[A\n",
      "Retraining epoch 0: 221it [05:26,  1.51s/it]\u001b[A\n",
      "Retraining epoch 0: 222it [05:28,  1.46s/it]\u001b[A\n",
      "Retraining epoch 0: 223it [05:29,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 224it [05:31,  1.43s/it]\u001b[A\n",
      "Retraining epoch 0: 225it [05:32,  1.51s/it]\u001b[A\n",
      "Retraining epoch 0: 226it [05:34,  1.46s/it]\u001b[A\n",
      "Retraining epoch 0: 227it [05:35,  1.48s/it]\u001b[A\n",
      "Retraining epoch 0: 228it [05:37,  1.48s/it]\u001b[A\n",
      "Retraining epoch 0: 229it [05:38,  1.48s/it]\u001b[A\n",
      "Retraining epoch 0: 230it [05:40,  1.52s/it]\u001b[A\n",
      "Retraining epoch 0: 231it [05:41,  1.43s/it]\u001b[A\n",
      "Retraining epoch 0: 232it [05:42,  1.42s/it]\u001b[A\n",
      "Retraining epoch 0: 233it [05:44,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 234it [05:45,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 235it [05:47,  1.43s/it]\u001b[A\n",
      "Retraining epoch 0: 236it [05:48,  1.49s/it]\u001b[A\n",
      "Retraining epoch 0: 237it [05:50,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 238it [05:51,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 239it [05:52,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 240it [05:54,  1.44s/it]\u001b[A\n",
      "Retraining epoch 0: 241it [05:55,  1.47s/it]\u001b[A\n",
      "Retraining epoch 0: 242it [05:57,  1.43s/it]\u001b[A\n",
      "Retraining epoch 0: 243it [05:58,  1.46s/it]\u001b[A\n",
      "Retraining epoch 0: 244it [06:00,  1.45s/it]\u001b[A\n",
      "Retraining epoch 0: 245it [06:01,  1.40s/it]\u001b[A\n",
      "Retraining epoch 0: 246it [06:02,  1.37s/it]\u001b[A\n",
      "Retraining epoch 0: 247it [06:04,  1.35s/it]\u001b[A\n",
      "Retraining epoch 0: 248it [06:05,  1.38s/it]\u001b[A\n",
      "Retraining epoch 0: 249it [06:06,  1.34s/it]\u001b[A\n",
      "Retraining epoch 0: 250it [06:08,  1.34s/it]\u001b[A\n",
      "Retraining epoch 0: 251it [06:09,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 252it [06:10,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 253it [06:12,  1.38s/it]\u001b[A\n",
      "Retraining epoch 0: 254it [06:13,  1.40s/it]\u001b[A\n",
      "Retraining epoch 0: 255it [06:15,  1.43s/it]\u001b[A\n",
      "Retraining epoch 0: 256it [06:16,  1.46s/it]\u001b[A\n",
      "Retraining epoch 0: 257it [06:17,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 258it [06:19,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 259it [06:20,  1.40s/it]\u001b[A\n",
      "Retraining epoch 0: 260it [06:22,  1.38s/it]\u001b[A\n",
      "Retraining epoch 0: 261it [06:23,  1.40s/it]\u001b[A\n",
      "Retraining epoch 0: 262it [06:24,  1.38s/it]\u001b[A\n",
      "Retraining epoch 0: 263it [06:26,  1.31s/it]\u001b[A\n",
      "Retraining epoch 0: 264it [06:27,  1.32s/it]\u001b[A\n",
      "Retraining epoch 0: 265it [06:28,  1.32s/it]\u001b[A\n",
      "Retraining epoch 0: 266it [06:30,  1.37s/it]\u001b[A\n",
      "Retraining epoch 0: 267it [06:31,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 268it [06:33,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 269it [06:34,  1.42s/it]\u001b[A\n",
      "Retraining epoch 0: 270it [06:35,  1.39s/it]\u001b[A\n",
      "Retraining epoch 0: 271it [06:37,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 272it [06:38,  1.40s/it]\u001b[A\n",
      "Retraining epoch 0: 273it [06:40,  1.42s/it]\u001b[A\n",
      "Retraining epoch 0: 274it [06:41,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 275it [06:42,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 276it [06:44,  1.36s/it]\u001b[A\n",
      "Retraining epoch 0: 277it [06:45,  1.37s/it]\u001b[A\n",
      "Retraining epoch 0: 278it [06:46,  1.37s/it]\u001b[A\n",
      "Retraining epoch 0: 279it [06:48,  1.38s/it]\u001b[A\n",
      "Retraining epoch 0: 280it [06:49,  1.40s/it]\u001b[A\n",
      "Retraining epoch 0: 281it [06:51,  1.41s/it]\u001b[A\n",
      "Retraining epoch 0: 282it [06:52,  1.46s/it]\u001b[A\n",
      "Epoch:   0%|                                                                                          | 0/1 [06:52<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "num_wrong = retrain(hd_model, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e442a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{24: [tensor(0.4663, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4694, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4867, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4838, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4757, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4633, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4486, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4817, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4671, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4582, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4386, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4625, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4449, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4726, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4675, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4356, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4500, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4841, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4759, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4588, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4786, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4675, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4537, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4858, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5062, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5145, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4635, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4844, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4851, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4642, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5002, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4347, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4812, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4459, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4468, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5055, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4827, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4841, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4531, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4483, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4798, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4763, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4742, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4296, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4948, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4510, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4142, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4464, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4335, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4742, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4440, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4788, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4520, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4741, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4794, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4791, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4838, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4413, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4845, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4503, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4738, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4602, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4923, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4461, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4838, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4996, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4636, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4817, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4563, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4423, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4799, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4418, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4870, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4781, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4830, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5002, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5136, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4670, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4293, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4555, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4317, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4926, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4805, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4268, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4528, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4426, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4659, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4935, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4829, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4301, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4602, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4538, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4675, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4622, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4839, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4601, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4635, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4417, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4978, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5028, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4491, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4794, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4454, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4508, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4987, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4469, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5077, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4707, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5060, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5011, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4872, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4351, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4886, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5066, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4365, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4711, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4991, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4845, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4693, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4732, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4721, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4749, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4924, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4526, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4943, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4870, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4510, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4901, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4656, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4639, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4372, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5111, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4868, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4684, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4853, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4539, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4851, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4331, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4956, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4649, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4328, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4486, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4564, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4433, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4600, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5101, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4333, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4635, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4603, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4615, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5058, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4845, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4672, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5101, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4231, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4816, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4493, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4509, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4442, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4963, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4516, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4461, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4466, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4597, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4346, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4436, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4924, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4786, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4774, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4884, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4541, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4449, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4868, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4829, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4613, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4590, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4833, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4854, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4647, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4530, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4558, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4904, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4376, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4524, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4769, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4810, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4262, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4579, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4367, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4715, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4839, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4858, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4823, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4466, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4930, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4803, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4550, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4391, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4872, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5086, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4492, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4708, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4509, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4448, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4580, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4620, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4414, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4510, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4561, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4764, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4595, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4466, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4711, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4519, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4329, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4991, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4461, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4791, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4738, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4606, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4767, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4390, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4665, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5185, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4496, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4534, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4492, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4434, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4811, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4104, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4792, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4428, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4801, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4912, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5016, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4649, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4687, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4471, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4385, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4873, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4674, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4593, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4685, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4782, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4768, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4443, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4274, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4630, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4709, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4577, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4900, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4400, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4501, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5005, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4829, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4757, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4597, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4716, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4523, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4923, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4780, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4535, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4508, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4690, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.5052, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4881, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4680, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4534, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4679, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4396, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4571, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4443, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4839, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4468, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4376, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4463, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4649, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4827, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4622, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4986, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.4470, device='cuda:0', dtype=torch.float64)],\n",
       " 36: [tensor(0.7536, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7454, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6762, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6711, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7605, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7658, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7762, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7665, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7903, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7807, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8080, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7622, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7059, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7655, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7843, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7180, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8277, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6837, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7668, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7631, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6926, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7664, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7487, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6831, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8183, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8268, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7478, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7568, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6818, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7685, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7881, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7581, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6834, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7387, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7847, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7106, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6777, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7551, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7536, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7596, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7618, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7064, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7312, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7361, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7840, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7408, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7628, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7749, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7340, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7761, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7383, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8076, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7360, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7671, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6590, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7827, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7393, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6994, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6861, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7680, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6774, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7680, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7706, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6887, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6784, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7723, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8035, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7774, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7520, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6987, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6873, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7057, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7888, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7204, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6900, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7880, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7122, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7717, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7939, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7674, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7163, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8024, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7093, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7434, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8053, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7365, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7650, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7596, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6874, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7414, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7977, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7968, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7625, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7701, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6779, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7413, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7540, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7696, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7709, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7794, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7746, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6505, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6880, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7404, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7877, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7132, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8035, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7425, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7478, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7723, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7310, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7158, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8081, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7810, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7415, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7513, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7654, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6815, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7937, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6932, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7673, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8102, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7214, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7558, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8216, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6770, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7793, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6863, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7626, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7542, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7285, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7297, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7560, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6812, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6836, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8061, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6741, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7464, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7813, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7709, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7696, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7487, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7758, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7584, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7656, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7097, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7532, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7523, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7438, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7631, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7444, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6722, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8342, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7450, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7397, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7863, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7437, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7662, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7666, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7558, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7969, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7951, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7531, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6800, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7438, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8218, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8221, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7235, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6834, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7387, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6793, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7132, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7425, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6818, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7345, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7633, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7328, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7578, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7375, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7936, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7120, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7025, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7631, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7273, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7288, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6861, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7746, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7439, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7505, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7591, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8366, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6724, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6828, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6826, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7228, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7915, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7718, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7410, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7684, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6811, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7772, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7642, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7536, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7620, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6979, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7716, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7951, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7515, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8204, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8335, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7147, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7426, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7662, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7826, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7857, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7389, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7445, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7467, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6850, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7604, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8106, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7652, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7826, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7658, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8020, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7834, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7709, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7417, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7727, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7582, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7754, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6803, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7596, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6839, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8015, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8010, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7719, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7985, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7857, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8037, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6796, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7621, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7349, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8037, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7496, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7198, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7488, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7300, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7506, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8037, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7586, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6826, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8052, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7637, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7709, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7787, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7931, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7003, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7825, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8405, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7529, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7624, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7986, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7322, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7576, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8036, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6770, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7604, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7288, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8295, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7830, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8099, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7773, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6843, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7716, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7412, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6938, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7693, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6725, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.7678, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.6900, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.8215, device='cuda:0', dtype=torch.float64)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hd_model.feature_extractor.model.waffleiron.cka_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a0b296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:  tensor(0.4104, device='cuda:0', dtype=torch.float64)\n",
      "max:  tensor(0.5185, device='cuda:0', dtype=torch.float64)\n",
      "std:  0.021384883486009927\n",
      "mean:  0.4668434063660229\n"
     ]
    }
   ],
   "source": [
    "cka_24 = hd_model.feature_extractor.model.waffleiron.cka_losses[24]\n",
    "print(\"min: \", min(cka_24))\n",
    "print(\"max: \", max(cka_24))\n",
    "np_cka_24 = np.array([i.cpu() for i in cka_24])\n",
    "print(\"std: \", np.std(np_cka_24))\n",
    "print(\"mean: \", np.mean(np_cka_24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d70bfb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample data\n",
    "data = np_cka_24\n",
    "print(data.shape)\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Data')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604f8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_cka_24_filt = np_cka_24 < np.mean(np_cka_24) - np.std(np_cka_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ba3b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:  tensor(0.6505, device='cuda:0', dtype=torch.float64)\n",
      "max:  tensor(0.8405, device='cuda:0', dtype=torch.float64)\n",
      "std:  0.04117572159578051\n",
      "mean:  0.7502839448897317\n"
     ]
    }
   ],
   "source": [
    "cka_36 = hd_model.feature_extractor.model.waffleiron.cka_losses[36]\n",
    "print(\"min: \", min(cka_36))\n",
    "print(\"max: \", max(cka_36))\n",
    "np_cka_36 = np.array([i.cpu() for i in cka_36])\n",
    "print(\"std: \", np.std(np_cka_36))\n",
    "print(\"mean: \", np.mean(np_cka_36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26c52164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample data\n",
    "data = np_cka_36\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Data')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e3c506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_cka_36_filt = np_cka_36 < np.mean(np_cka_36) - np.std(np_cka_36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3fc6b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample data\n",
    "data = np_cka_36[np_cka_24_filt]\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Data')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc840dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape) ## Amount of values that are left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b10553a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_cka_36[[i & j for i,j in zip(np_cka_24_filt, np_cka_36_filt)]].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
