{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd417ca",
   "metadata": {},
   "source": [
    "# Get WaffleIron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afc500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch.scatter_reduce for 3D to 2D projection.\n",
      "Using torch.scatter_reduce for 3D to 2D projection.\n"
     ]
    }
   ],
   "source": [
    "from models.waffleiron.segmenter import Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12df3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Segmenter(\n",
    "    input_channels=5,\n",
    "    feat_channels=768,\n",
    "    depth=48,\n",
    "    grid_shape=[[256, 256], [256, 32], [256, 32]],\n",
    "    nb_class=16, # class for prediction\n",
    "    #drop_path_prob=config[\"waffleiron\"][\"drop_path\"],\n",
    "    layer_norm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff7e82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load pretrained model\n",
    "ckpt = torch.load('./saved_models/ckpt_last_scalr.pth', map_location=\"cuda:0\")\n",
    "ckpt = ckpt[\"net\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4933ff55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['module.embed.norm.weight', 'module.embed.norm.bias', 'module.embed.norm.running_mean', 'module.embed.norm.running_var', 'module.embed.norm.num_batches_tracked', 'module.embed.conv1.weight', 'module.embed.conv1.bias', 'module.embed.conv2.0.weight', 'module.embed.conv2.0.bias', 'module.embed.conv2.0.running_mean', 'module.embed.conv2.0.running_var', 'module.embed.conv2.0.num_batches_tracked', 'module.embed.conv2.1.weight', 'module.embed.conv2.2.weight', 'module.embed.conv2.2.bias', 'module.embed.conv2.2.running_mean', 'module.embed.conv2.2.running_var', 'module.embed.conv2.2.num_batches_tracked', 'module.embed.conv2.4.weight', 'module.embed.final.weight', 'module.embed.final.bias', 'module.waffleiron.channel_mix.0.scale.weight', 'module.waffleiron.channel_mix.0.norm.weight', 'module.waffleiron.channel_mix.0.norm.bias', 'module.waffleiron.channel_mix.0.mlp.0.weight', 'module.waffleiron.channel_mix.0.mlp.0.bias', 'module.waffleiron.channel_mix.0.mlp.2.weight', 'module.waffleiron.channel_mix.0.mlp.2.bias', 'module.waffleiron.channel_mix.1.scale.weight', 'module.waffleiron.channel_mix.1.norm.weight', 'module.waffleiron.channel_mix.1.norm.bias', 'module.waffleiron.channel_mix.1.mlp.0.weight', 'module.waffleiron.channel_mix.1.mlp.0.bias', 'module.waffleiron.channel_mix.1.mlp.2.weight', 'module.waffleiron.channel_mix.1.mlp.2.bias', 'module.waffleiron.channel_mix.2.scale.weight', 'module.waffleiron.channel_mix.2.norm.weight', 'module.waffleiron.channel_mix.2.norm.bias', 'module.waffleiron.channel_mix.2.mlp.0.weight', 'module.waffleiron.channel_mix.2.mlp.0.bias', 'module.waffleiron.channel_mix.2.mlp.2.weight', 'module.waffleiron.channel_mix.2.mlp.2.bias', 'module.waffleiron.channel_mix.3.scale.weight', 'module.waffleiron.channel_mix.3.norm.weight', 'module.waffleiron.channel_mix.3.norm.bias', 'module.waffleiron.channel_mix.3.mlp.0.weight', 'module.waffleiron.channel_mix.3.mlp.0.bias', 'module.waffleiron.channel_mix.3.mlp.2.weight', 'module.waffleiron.channel_mix.3.mlp.2.bias', 'module.waffleiron.channel_mix.4.scale.weight', 'module.waffleiron.channel_mix.4.norm.weight', 'module.waffleiron.channel_mix.4.norm.bias', 'module.waffleiron.channel_mix.4.mlp.0.weight', 'module.waffleiron.channel_mix.4.mlp.0.bias', 'module.waffleiron.channel_mix.4.mlp.2.weight', 'module.waffleiron.channel_mix.4.mlp.2.bias', 'module.waffleiron.channel_mix.5.scale.weight', 'module.waffleiron.channel_mix.5.norm.weight', 'module.waffleiron.channel_mix.5.norm.bias', 'module.waffleiron.channel_mix.5.mlp.0.weight', 'module.waffleiron.channel_mix.5.mlp.0.bias', 'module.waffleiron.channel_mix.5.mlp.2.weight', 'module.waffleiron.channel_mix.5.mlp.2.bias', 'module.waffleiron.channel_mix.6.scale.weight', 'module.waffleiron.channel_mix.6.norm.weight', 'module.waffleiron.channel_mix.6.norm.bias', 'module.waffleiron.channel_mix.6.mlp.0.weight', 'module.waffleiron.channel_mix.6.mlp.0.bias', 'module.waffleiron.channel_mix.6.mlp.2.weight', 'module.waffleiron.channel_mix.6.mlp.2.bias', 'module.waffleiron.channel_mix.7.scale.weight', 'module.waffleiron.channel_mix.7.norm.weight', 'module.waffleiron.channel_mix.7.norm.bias', 'module.waffleiron.channel_mix.7.mlp.0.weight', 'module.waffleiron.channel_mix.7.mlp.0.bias', 'module.waffleiron.channel_mix.7.mlp.2.weight', 'module.waffleiron.channel_mix.7.mlp.2.bias', 'module.waffleiron.channel_mix.8.scale.weight', 'module.waffleiron.channel_mix.8.norm.weight', 'module.waffleiron.channel_mix.8.norm.bias', 'module.waffleiron.channel_mix.8.mlp.0.weight', 'module.waffleiron.channel_mix.8.mlp.0.bias', 'module.waffleiron.channel_mix.8.mlp.2.weight', 'module.waffleiron.channel_mix.8.mlp.2.bias', 'module.waffleiron.channel_mix.9.scale.weight', 'module.waffleiron.channel_mix.9.norm.weight', 'module.waffleiron.channel_mix.9.norm.bias', 'module.waffleiron.channel_mix.9.mlp.0.weight', 'module.waffleiron.channel_mix.9.mlp.0.bias', 'module.waffleiron.channel_mix.9.mlp.2.weight', 'module.waffleiron.channel_mix.9.mlp.2.bias', 'module.waffleiron.channel_mix.10.scale.weight', 'module.waffleiron.channel_mix.10.norm.weight', 'module.waffleiron.channel_mix.10.norm.bias', 'module.waffleiron.channel_mix.10.mlp.0.weight', 'module.waffleiron.channel_mix.10.mlp.0.bias', 'module.waffleiron.channel_mix.10.mlp.2.weight', 'module.waffleiron.channel_mix.10.mlp.2.bias', 'module.waffleiron.channel_mix.11.scale.weight', 'module.waffleiron.channel_mix.11.norm.weight', 'module.waffleiron.channel_mix.11.norm.bias', 'module.waffleiron.channel_mix.11.mlp.0.weight', 'module.waffleiron.channel_mix.11.mlp.0.bias', 'module.waffleiron.channel_mix.11.mlp.2.weight', 'module.waffleiron.channel_mix.11.mlp.2.bias', 'module.waffleiron.channel_mix.12.scale.weight', 'module.waffleiron.channel_mix.12.norm.weight', 'module.waffleiron.channel_mix.12.norm.bias', 'module.waffleiron.channel_mix.12.mlp.0.weight', 'module.waffleiron.channel_mix.12.mlp.0.bias', 'module.waffleiron.channel_mix.12.mlp.2.weight', 'module.waffleiron.channel_mix.12.mlp.2.bias', 'module.waffleiron.channel_mix.13.scale.weight', 'module.waffleiron.channel_mix.13.norm.weight', 'module.waffleiron.channel_mix.13.norm.bias', 'module.waffleiron.channel_mix.13.mlp.0.weight', 'module.waffleiron.channel_mix.13.mlp.0.bias', 'module.waffleiron.channel_mix.13.mlp.2.weight', 'module.waffleiron.channel_mix.13.mlp.2.bias', 'module.waffleiron.channel_mix.14.scale.weight', 'module.waffleiron.channel_mix.14.norm.weight', 'module.waffleiron.channel_mix.14.norm.bias', 'module.waffleiron.channel_mix.14.mlp.0.weight', 'module.waffleiron.channel_mix.14.mlp.0.bias', 'module.waffleiron.channel_mix.14.mlp.2.weight', 'module.waffleiron.channel_mix.14.mlp.2.bias', 'module.waffleiron.channel_mix.15.scale.weight', 'module.waffleiron.channel_mix.15.norm.weight', 'module.waffleiron.channel_mix.15.norm.bias', 'module.waffleiron.channel_mix.15.mlp.0.weight', 'module.waffleiron.channel_mix.15.mlp.0.bias', 'module.waffleiron.channel_mix.15.mlp.2.weight', 'module.waffleiron.channel_mix.15.mlp.2.bias', 'module.waffleiron.channel_mix.16.scale.weight', 'module.waffleiron.channel_mix.16.norm.weight', 'module.waffleiron.channel_mix.16.norm.bias', 'module.waffleiron.channel_mix.16.mlp.0.weight', 'module.waffleiron.channel_mix.16.mlp.0.bias', 'module.waffleiron.channel_mix.16.mlp.2.weight', 'module.waffleiron.channel_mix.16.mlp.2.bias', 'module.waffleiron.channel_mix.17.scale.weight', 'module.waffleiron.channel_mix.17.norm.weight', 'module.waffleiron.channel_mix.17.norm.bias', 'module.waffleiron.channel_mix.17.mlp.0.weight', 'module.waffleiron.channel_mix.17.mlp.0.bias', 'module.waffleiron.channel_mix.17.mlp.2.weight', 'module.waffleiron.channel_mix.17.mlp.2.bias', 'module.waffleiron.channel_mix.18.scale.weight', 'module.waffleiron.channel_mix.18.norm.weight', 'module.waffleiron.channel_mix.18.norm.bias', 'module.waffleiron.channel_mix.18.mlp.0.weight', 'module.waffleiron.channel_mix.18.mlp.0.bias', 'module.waffleiron.channel_mix.18.mlp.2.weight', 'module.waffleiron.channel_mix.18.mlp.2.bias', 'module.waffleiron.channel_mix.19.scale.weight', 'module.waffleiron.channel_mix.19.norm.weight', 'module.waffleiron.channel_mix.19.norm.bias', 'module.waffleiron.channel_mix.19.mlp.0.weight', 'module.waffleiron.channel_mix.19.mlp.0.bias', 'module.waffleiron.channel_mix.19.mlp.2.weight', 'module.waffleiron.channel_mix.19.mlp.2.bias', 'module.waffleiron.channel_mix.20.scale.weight', 'module.waffleiron.channel_mix.20.norm.weight', 'module.waffleiron.channel_mix.20.norm.bias', 'module.waffleiron.channel_mix.20.mlp.0.weight', 'module.waffleiron.channel_mix.20.mlp.0.bias', 'module.waffleiron.channel_mix.20.mlp.2.weight', 'module.waffleiron.channel_mix.20.mlp.2.bias', 'module.waffleiron.channel_mix.21.scale.weight', 'module.waffleiron.channel_mix.21.norm.weight', 'module.waffleiron.channel_mix.21.norm.bias', 'module.waffleiron.channel_mix.21.mlp.0.weight', 'module.waffleiron.channel_mix.21.mlp.0.bias', 'module.waffleiron.channel_mix.21.mlp.2.weight', 'module.waffleiron.channel_mix.21.mlp.2.bias', 'module.waffleiron.channel_mix.22.scale.weight', 'module.waffleiron.channel_mix.22.norm.weight', 'module.waffleiron.channel_mix.22.norm.bias', 'module.waffleiron.channel_mix.22.mlp.0.weight', 'module.waffleiron.channel_mix.22.mlp.0.bias', 'module.waffleiron.channel_mix.22.mlp.2.weight', 'module.waffleiron.channel_mix.22.mlp.2.bias', 'module.waffleiron.channel_mix.23.scale.weight', 'module.waffleiron.channel_mix.23.norm.weight', 'module.waffleiron.channel_mix.23.norm.bias', 'module.waffleiron.channel_mix.23.mlp.0.weight', 'module.waffleiron.channel_mix.23.mlp.0.bias', 'module.waffleiron.channel_mix.23.mlp.2.weight', 'module.waffleiron.channel_mix.23.mlp.2.bias', 'module.waffleiron.channel_mix.24.scale.weight', 'module.waffleiron.channel_mix.24.norm.weight', 'module.waffleiron.channel_mix.24.norm.bias', 'module.waffleiron.channel_mix.24.mlp.0.weight', 'module.waffleiron.channel_mix.24.mlp.0.bias', 'module.waffleiron.channel_mix.24.mlp.2.weight', 'module.waffleiron.channel_mix.24.mlp.2.bias', 'module.waffleiron.channel_mix.25.scale.weight', 'module.waffleiron.channel_mix.25.norm.weight', 'module.waffleiron.channel_mix.25.norm.bias', 'module.waffleiron.channel_mix.25.mlp.0.weight', 'module.waffleiron.channel_mix.25.mlp.0.bias', 'module.waffleiron.channel_mix.25.mlp.2.weight', 'module.waffleiron.channel_mix.25.mlp.2.bias', 'module.waffleiron.channel_mix.26.scale.weight', 'module.waffleiron.channel_mix.26.norm.weight', 'module.waffleiron.channel_mix.26.norm.bias', 'module.waffleiron.channel_mix.26.mlp.0.weight', 'module.waffleiron.channel_mix.26.mlp.0.bias', 'module.waffleiron.channel_mix.26.mlp.2.weight', 'module.waffleiron.channel_mix.26.mlp.2.bias', 'module.waffleiron.channel_mix.27.scale.weight', 'module.waffleiron.channel_mix.27.norm.weight', 'module.waffleiron.channel_mix.27.norm.bias', 'module.waffleiron.channel_mix.27.mlp.0.weight', 'module.waffleiron.channel_mix.27.mlp.0.bias', 'module.waffleiron.channel_mix.27.mlp.2.weight', 'module.waffleiron.channel_mix.27.mlp.2.bias', 'module.waffleiron.channel_mix.28.scale.weight', 'module.waffleiron.channel_mix.28.norm.weight', 'module.waffleiron.channel_mix.28.norm.bias', 'module.waffleiron.channel_mix.28.mlp.0.weight', 'module.waffleiron.channel_mix.28.mlp.0.bias', 'module.waffleiron.channel_mix.28.mlp.2.weight', 'module.waffleiron.channel_mix.28.mlp.2.bias', 'module.waffleiron.channel_mix.29.scale.weight', 'module.waffleiron.channel_mix.29.norm.weight', 'module.waffleiron.channel_mix.29.norm.bias', 'module.waffleiron.channel_mix.29.mlp.0.weight', 'module.waffleiron.channel_mix.29.mlp.0.bias', 'module.waffleiron.channel_mix.29.mlp.2.weight', 'module.waffleiron.channel_mix.29.mlp.2.bias', 'module.waffleiron.channel_mix.30.scale.weight', 'module.waffleiron.channel_mix.30.norm.weight', 'module.waffleiron.channel_mix.30.norm.bias', 'module.waffleiron.channel_mix.30.mlp.0.weight', 'module.waffleiron.channel_mix.30.mlp.0.bias', 'module.waffleiron.channel_mix.30.mlp.2.weight', 'module.waffleiron.channel_mix.30.mlp.2.bias', 'module.waffleiron.channel_mix.31.scale.weight', 'module.waffleiron.channel_mix.31.norm.weight', 'module.waffleiron.channel_mix.31.norm.bias', 'module.waffleiron.channel_mix.31.mlp.0.weight', 'module.waffleiron.channel_mix.31.mlp.0.bias', 'module.waffleiron.channel_mix.31.mlp.2.weight', 'module.waffleiron.channel_mix.31.mlp.2.bias', 'module.waffleiron.channel_mix.32.scale.weight', 'module.waffleiron.channel_mix.32.norm.weight', 'module.waffleiron.channel_mix.32.norm.bias', 'module.waffleiron.channel_mix.32.mlp.0.weight', 'module.waffleiron.channel_mix.32.mlp.0.bias', 'module.waffleiron.channel_mix.32.mlp.2.weight', 'module.waffleiron.channel_mix.32.mlp.2.bias', 'module.waffleiron.channel_mix.33.scale.weight', 'module.waffleiron.channel_mix.33.norm.weight', 'module.waffleiron.channel_mix.33.norm.bias', 'module.waffleiron.channel_mix.33.mlp.0.weight', 'module.waffleiron.channel_mix.33.mlp.0.bias', 'module.waffleiron.channel_mix.33.mlp.2.weight', 'module.waffleiron.channel_mix.33.mlp.2.bias', 'module.waffleiron.channel_mix.34.scale.weight', 'module.waffleiron.channel_mix.34.norm.weight', 'module.waffleiron.channel_mix.34.norm.bias', 'module.waffleiron.channel_mix.34.mlp.0.weight', 'module.waffleiron.channel_mix.34.mlp.0.bias', 'module.waffleiron.channel_mix.34.mlp.2.weight', 'module.waffleiron.channel_mix.34.mlp.2.bias', 'module.waffleiron.channel_mix.35.scale.weight', 'module.waffleiron.channel_mix.35.norm.weight', 'module.waffleiron.channel_mix.35.norm.bias', 'module.waffleiron.channel_mix.35.mlp.0.weight', 'module.waffleiron.channel_mix.35.mlp.0.bias', 'module.waffleiron.channel_mix.35.mlp.2.weight', 'module.waffleiron.channel_mix.35.mlp.2.bias', 'module.waffleiron.channel_mix.36.scale.weight', 'module.waffleiron.channel_mix.36.norm.weight', 'module.waffleiron.channel_mix.36.norm.bias', 'module.waffleiron.channel_mix.36.mlp.0.weight', 'module.waffleiron.channel_mix.36.mlp.0.bias', 'module.waffleiron.channel_mix.36.mlp.2.weight', 'module.waffleiron.channel_mix.36.mlp.2.bias', 'module.waffleiron.channel_mix.37.scale.weight', 'module.waffleiron.channel_mix.37.norm.weight', 'module.waffleiron.channel_mix.37.norm.bias', 'module.waffleiron.channel_mix.37.mlp.0.weight', 'module.waffleiron.channel_mix.37.mlp.0.bias', 'module.waffleiron.channel_mix.37.mlp.2.weight', 'module.waffleiron.channel_mix.37.mlp.2.bias', 'module.waffleiron.channel_mix.38.scale.weight', 'module.waffleiron.channel_mix.38.norm.weight', 'module.waffleiron.channel_mix.38.norm.bias', 'module.waffleiron.channel_mix.38.mlp.0.weight', 'module.waffleiron.channel_mix.38.mlp.0.bias', 'module.waffleiron.channel_mix.38.mlp.2.weight', 'module.waffleiron.channel_mix.38.mlp.2.bias', 'module.waffleiron.channel_mix.39.scale.weight', 'module.waffleiron.channel_mix.39.norm.weight', 'module.waffleiron.channel_mix.39.norm.bias', 'module.waffleiron.channel_mix.39.mlp.0.weight', 'module.waffleiron.channel_mix.39.mlp.0.bias', 'module.waffleiron.channel_mix.39.mlp.2.weight', 'module.waffleiron.channel_mix.39.mlp.2.bias', 'module.waffleiron.channel_mix.40.scale.weight', 'module.waffleiron.channel_mix.40.norm.weight', 'module.waffleiron.channel_mix.40.norm.bias', 'module.waffleiron.channel_mix.40.mlp.0.weight', 'module.waffleiron.channel_mix.40.mlp.0.bias', 'module.waffleiron.channel_mix.40.mlp.2.weight', 'module.waffleiron.channel_mix.40.mlp.2.bias', 'module.waffleiron.channel_mix.41.scale.weight', 'module.waffleiron.channel_mix.41.norm.weight', 'module.waffleiron.channel_mix.41.norm.bias', 'module.waffleiron.channel_mix.41.mlp.0.weight', 'module.waffleiron.channel_mix.41.mlp.0.bias', 'module.waffleiron.channel_mix.41.mlp.2.weight', 'module.waffleiron.channel_mix.41.mlp.2.bias', 'module.waffleiron.channel_mix.42.scale.weight', 'module.waffleiron.channel_mix.42.norm.weight', 'module.waffleiron.channel_mix.42.norm.bias', 'module.waffleiron.channel_mix.42.mlp.0.weight', 'module.waffleiron.channel_mix.42.mlp.0.bias', 'module.waffleiron.channel_mix.42.mlp.2.weight', 'module.waffleiron.channel_mix.42.mlp.2.bias', 'module.waffleiron.channel_mix.43.scale.weight', 'module.waffleiron.channel_mix.43.norm.weight', 'module.waffleiron.channel_mix.43.norm.bias', 'module.waffleiron.channel_mix.43.mlp.0.weight', 'module.waffleiron.channel_mix.43.mlp.0.bias', 'module.waffleiron.channel_mix.43.mlp.2.weight', 'module.waffleiron.channel_mix.43.mlp.2.bias', 'module.waffleiron.channel_mix.44.scale.weight', 'module.waffleiron.channel_mix.44.norm.weight', 'module.waffleiron.channel_mix.44.norm.bias', 'module.waffleiron.channel_mix.44.mlp.0.weight', 'module.waffleiron.channel_mix.44.mlp.0.bias', 'module.waffleiron.channel_mix.44.mlp.2.weight', 'module.waffleiron.channel_mix.44.mlp.2.bias', 'module.waffleiron.channel_mix.45.scale.weight', 'module.waffleiron.channel_mix.45.norm.weight', 'module.waffleiron.channel_mix.45.norm.bias', 'module.waffleiron.channel_mix.45.mlp.0.weight', 'module.waffleiron.channel_mix.45.mlp.0.bias', 'module.waffleiron.channel_mix.45.mlp.2.weight', 'module.waffleiron.channel_mix.45.mlp.2.bias', 'module.waffleiron.channel_mix.46.scale.weight', 'module.waffleiron.channel_mix.46.norm.weight', 'module.waffleiron.channel_mix.46.norm.bias', 'module.waffleiron.channel_mix.46.mlp.0.weight', 'module.waffleiron.channel_mix.46.mlp.0.bias', 'module.waffleiron.channel_mix.46.mlp.2.weight', 'module.waffleiron.channel_mix.46.mlp.2.bias', 'module.waffleiron.channel_mix.47.scale.weight', 'module.waffleiron.channel_mix.47.norm.weight', 'module.waffleiron.channel_mix.47.norm.bias', 'module.waffleiron.channel_mix.47.mlp.0.weight', 'module.waffleiron.channel_mix.47.mlp.0.bias', 'module.waffleiron.channel_mix.47.mlp.2.weight', 'module.waffleiron.channel_mix.47.mlp.2.bias', 'module.waffleiron.spatial_mix.0.scale.weight', 'module.waffleiron.spatial_mix.0.norm.weight', 'module.waffleiron.spatial_mix.0.norm.bias', 'module.waffleiron.spatial_mix.0.ffn.0.weight', 'module.waffleiron.spatial_mix.0.ffn.0.bias', 'module.waffleiron.spatial_mix.0.ffn.2.weight', 'module.waffleiron.spatial_mix.0.ffn.2.bias', 'module.waffleiron.spatial_mix.1.scale.weight', 'module.waffleiron.spatial_mix.1.norm.weight', 'module.waffleiron.spatial_mix.1.norm.bias', 'module.waffleiron.spatial_mix.1.ffn.0.weight', 'module.waffleiron.spatial_mix.1.ffn.0.bias', 'module.waffleiron.spatial_mix.1.ffn.2.weight', 'module.waffleiron.spatial_mix.1.ffn.2.bias', 'module.waffleiron.spatial_mix.2.scale.weight', 'module.waffleiron.spatial_mix.2.norm.weight', 'module.waffleiron.spatial_mix.2.norm.bias', 'module.waffleiron.spatial_mix.2.ffn.0.weight', 'module.waffleiron.spatial_mix.2.ffn.0.bias', 'module.waffleiron.spatial_mix.2.ffn.2.weight', 'module.waffleiron.spatial_mix.2.ffn.2.bias', 'module.waffleiron.spatial_mix.3.scale.weight', 'module.waffleiron.spatial_mix.3.norm.weight', 'module.waffleiron.spatial_mix.3.norm.bias', 'module.waffleiron.spatial_mix.3.ffn.0.weight', 'module.waffleiron.spatial_mix.3.ffn.0.bias', 'module.waffleiron.spatial_mix.3.ffn.2.weight', 'module.waffleiron.spatial_mix.3.ffn.2.bias', 'module.waffleiron.spatial_mix.4.scale.weight', 'module.waffleiron.spatial_mix.4.norm.weight', 'module.waffleiron.spatial_mix.4.norm.bias', 'module.waffleiron.spatial_mix.4.ffn.0.weight', 'module.waffleiron.spatial_mix.4.ffn.0.bias', 'module.waffleiron.spatial_mix.4.ffn.2.weight', 'module.waffleiron.spatial_mix.4.ffn.2.bias', 'module.waffleiron.spatial_mix.5.scale.weight', 'module.waffleiron.spatial_mix.5.norm.weight', 'module.waffleiron.spatial_mix.5.norm.bias', 'module.waffleiron.spatial_mix.5.ffn.0.weight', 'module.waffleiron.spatial_mix.5.ffn.0.bias', 'module.waffleiron.spatial_mix.5.ffn.2.weight', 'module.waffleiron.spatial_mix.5.ffn.2.bias', 'module.waffleiron.spatial_mix.6.scale.weight', 'module.waffleiron.spatial_mix.6.norm.weight', 'module.waffleiron.spatial_mix.6.norm.bias', 'module.waffleiron.spatial_mix.6.ffn.0.weight', 'module.waffleiron.spatial_mix.6.ffn.0.bias', 'module.waffleiron.spatial_mix.6.ffn.2.weight', 'module.waffleiron.spatial_mix.6.ffn.2.bias', 'module.waffleiron.spatial_mix.7.scale.weight', 'module.waffleiron.spatial_mix.7.norm.weight', 'module.waffleiron.spatial_mix.7.norm.bias', 'module.waffleiron.spatial_mix.7.ffn.0.weight', 'module.waffleiron.spatial_mix.7.ffn.0.bias', 'module.waffleiron.spatial_mix.7.ffn.2.weight', 'module.waffleiron.spatial_mix.7.ffn.2.bias', 'module.waffleiron.spatial_mix.8.scale.weight', 'module.waffleiron.spatial_mix.8.norm.weight', 'module.waffleiron.spatial_mix.8.norm.bias', 'module.waffleiron.spatial_mix.8.ffn.0.weight', 'module.waffleiron.spatial_mix.8.ffn.0.bias', 'module.waffleiron.spatial_mix.8.ffn.2.weight', 'module.waffleiron.spatial_mix.8.ffn.2.bias', 'module.waffleiron.spatial_mix.9.scale.weight', 'module.waffleiron.spatial_mix.9.norm.weight', 'module.waffleiron.spatial_mix.9.norm.bias', 'module.waffleiron.spatial_mix.9.ffn.0.weight', 'module.waffleiron.spatial_mix.9.ffn.0.bias', 'module.waffleiron.spatial_mix.9.ffn.2.weight', 'module.waffleiron.spatial_mix.9.ffn.2.bias', 'module.waffleiron.spatial_mix.10.scale.weight', 'module.waffleiron.spatial_mix.10.norm.weight', 'module.waffleiron.spatial_mix.10.norm.bias', 'module.waffleiron.spatial_mix.10.ffn.0.weight', 'module.waffleiron.spatial_mix.10.ffn.0.bias', 'module.waffleiron.spatial_mix.10.ffn.2.weight', 'module.waffleiron.spatial_mix.10.ffn.2.bias', 'module.waffleiron.spatial_mix.11.scale.weight', 'module.waffleiron.spatial_mix.11.norm.weight', 'module.waffleiron.spatial_mix.11.norm.bias', 'module.waffleiron.spatial_mix.11.ffn.0.weight', 'module.waffleiron.spatial_mix.11.ffn.0.bias', 'module.waffleiron.spatial_mix.11.ffn.2.weight', 'module.waffleiron.spatial_mix.11.ffn.2.bias', 'module.waffleiron.spatial_mix.12.scale.weight', 'module.waffleiron.spatial_mix.12.norm.weight', 'module.waffleiron.spatial_mix.12.norm.bias', 'module.waffleiron.spatial_mix.12.ffn.0.weight', 'module.waffleiron.spatial_mix.12.ffn.0.bias', 'module.waffleiron.spatial_mix.12.ffn.2.weight', 'module.waffleiron.spatial_mix.12.ffn.2.bias', 'module.waffleiron.spatial_mix.13.scale.weight', 'module.waffleiron.spatial_mix.13.norm.weight', 'module.waffleiron.spatial_mix.13.norm.bias', 'module.waffleiron.spatial_mix.13.ffn.0.weight', 'module.waffleiron.spatial_mix.13.ffn.0.bias', 'module.waffleiron.spatial_mix.13.ffn.2.weight', 'module.waffleiron.spatial_mix.13.ffn.2.bias', 'module.waffleiron.spatial_mix.14.scale.weight', 'module.waffleiron.spatial_mix.14.norm.weight', 'module.waffleiron.spatial_mix.14.norm.bias', 'module.waffleiron.spatial_mix.14.ffn.0.weight', 'module.waffleiron.spatial_mix.14.ffn.0.bias', 'module.waffleiron.spatial_mix.14.ffn.2.weight', 'module.waffleiron.spatial_mix.14.ffn.2.bias', 'module.waffleiron.spatial_mix.15.scale.weight', 'module.waffleiron.spatial_mix.15.norm.weight', 'module.waffleiron.spatial_mix.15.norm.bias', 'module.waffleiron.spatial_mix.15.ffn.0.weight', 'module.waffleiron.spatial_mix.15.ffn.0.bias', 'module.waffleiron.spatial_mix.15.ffn.2.weight', 'module.waffleiron.spatial_mix.15.ffn.2.bias', 'module.waffleiron.spatial_mix.16.scale.weight', 'module.waffleiron.spatial_mix.16.norm.weight', 'module.waffleiron.spatial_mix.16.norm.bias', 'module.waffleiron.spatial_mix.16.ffn.0.weight', 'module.waffleiron.spatial_mix.16.ffn.0.bias', 'module.waffleiron.spatial_mix.16.ffn.2.weight', 'module.waffleiron.spatial_mix.16.ffn.2.bias', 'module.waffleiron.spatial_mix.17.scale.weight', 'module.waffleiron.spatial_mix.17.norm.weight', 'module.waffleiron.spatial_mix.17.norm.bias', 'module.waffleiron.spatial_mix.17.ffn.0.weight', 'module.waffleiron.spatial_mix.17.ffn.0.bias', 'module.waffleiron.spatial_mix.17.ffn.2.weight', 'module.waffleiron.spatial_mix.17.ffn.2.bias', 'module.waffleiron.spatial_mix.18.scale.weight', 'module.waffleiron.spatial_mix.18.norm.weight', 'module.waffleiron.spatial_mix.18.norm.bias', 'module.waffleiron.spatial_mix.18.ffn.0.weight', 'module.waffleiron.spatial_mix.18.ffn.0.bias', 'module.waffleiron.spatial_mix.18.ffn.2.weight', 'module.waffleiron.spatial_mix.18.ffn.2.bias', 'module.waffleiron.spatial_mix.19.scale.weight', 'module.waffleiron.spatial_mix.19.norm.weight', 'module.waffleiron.spatial_mix.19.norm.bias', 'module.waffleiron.spatial_mix.19.ffn.0.weight', 'module.waffleiron.spatial_mix.19.ffn.0.bias', 'module.waffleiron.spatial_mix.19.ffn.2.weight', 'module.waffleiron.spatial_mix.19.ffn.2.bias', 'module.waffleiron.spatial_mix.20.scale.weight', 'module.waffleiron.spatial_mix.20.norm.weight', 'module.waffleiron.spatial_mix.20.norm.bias', 'module.waffleiron.spatial_mix.20.ffn.0.weight', 'module.waffleiron.spatial_mix.20.ffn.0.bias', 'module.waffleiron.spatial_mix.20.ffn.2.weight', 'module.waffleiron.spatial_mix.20.ffn.2.bias', 'module.waffleiron.spatial_mix.21.scale.weight', 'module.waffleiron.spatial_mix.21.norm.weight', 'module.waffleiron.spatial_mix.21.norm.bias', 'module.waffleiron.spatial_mix.21.ffn.0.weight', 'module.waffleiron.spatial_mix.21.ffn.0.bias', 'module.waffleiron.spatial_mix.21.ffn.2.weight', 'module.waffleiron.spatial_mix.21.ffn.2.bias', 'module.waffleiron.spatial_mix.22.scale.weight', 'module.waffleiron.spatial_mix.22.norm.weight', 'module.waffleiron.spatial_mix.22.norm.bias', 'module.waffleiron.spatial_mix.22.ffn.0.weight', 'module.waffleiron.spatial_mix.22.ffn.0.bias', 'module.waffleiron.spatial_mix.22.ffn.2.weight', 'module.waffleiron.spatial_mix.22.ffn.2.bias', 'module.waffleiron.spatial_mix.23.scale.weight', 'module.waffleiron.spatial_mix.23.norm.weight', 'module.waffleiron.spatial_mix.23.norm.bias', 'module.waffleiron.spatial_mix.23.ffn.0.weight', 'module.waffleiron.spatial_mix.23.ffn.0.bias', 'module.waffleiron.spatial_mix.23.ffn.2.weight', 'module.waffleiron.spatial_mix.23.ffn.2.bias', 'module.waffleiron.spatial_mix.24.scale.weight', 'module.waffleiron.spatial_mix.24.norm.weight', 'module.waffleiron.spatial_mix.24.norm.bias', 'module.waffleiron.spatial_mix.24.ffn.0.weight', 'module.waffleiron.spatial_mix.24.ffn.0.bias', 'module.waffleiron.spatial_mix.24.ffn.2.weight', 'module.waffleiron.spatial_mix.24.ffn.2.bias', 'module.waffleiron.spatial_mix.25.scale.weight', 'module.waffleiron.spatial_mix.25.norm.weight', 'module.waffleiron.spatial_mix.25.norm.bias', 'module.waffleiron.spatial_mix.25.ffn.0.weight', 'module.waffleiron.spatial_mix.25.ffn.0.bias', 'module.waffleiron.spatial_mix.25.ffn.2.weight', 'module.waffleiron.spatial_mix.25.ffn.2.bias', 'module.waffleiron.spatial_mix.26.scale.weight', 'module.waffleiron.spatial_mix.26.norm.weight', 'module.waffleiron.spatial_mix.26.norm.bias', 'module.waffleiron.spatial_mix.26.ffn.0.weight', 'module.waffleiron.spatial_mix.26.ffn.0.bias', 'module.waffleiron.spatial_mix.26.ffn.2.weight', 'module.waffleiron.spatial_mix.26.ffn.2.bias', 'module.waffleiron.spatial_mix.27.scale.weight', 'module.waffleiron.spatial_mix.27.norm.weight', 'module.waffleiron.spatial_mix.27.norm.bias', 'module.waffleiron.spatial_mix.27.ffn.0.weight', 'module.waffleiron.spatial_mix.27.ffn.0.bias', 'module.waffleiron.spatial_mix.27.ffn.2.weight', 'module.waffleiron.spatial_mix.27.ffn.2.bias', 'module.waffleiron.spatial_mix.28.scale.weight', 'module.waffleiron.spatial_mix.28.norm.weight', 'module.waffleiron.spatial_mix.28.norm.bias', 'module.waffleiron.spatial_mix.28.ffn.0.weight', 'module.waffleiron.spatial_mix.28.ffn.0.bias', 'module.waffleiron.spatial_mix.28.ffn.2.weight', 'module.waffleiron.spatial_mix.28.ffn.2.bias', 'module.waffleiron.spatial_mix.29.scale.weight', 'module.waffleiron.spatial_mix.29.norm.weight', 'module.waffleiron.spatial_mix.29.norm.bias', 'module.waffleiron.spatial_mix.29.ffn.0.weight', 'module.waffleiron.spatial_mix.29.ffn.0.bias', 'module.waffleiron.spatial_mix.29.ffn.2.weight', 'module.waffleiron.spatial_mix.29.ffn.2.bias', 'module.waffleiron.spatial_mix.30.scale.weight', 'module.waffleiron.spatial_mix.30.norm.weight', 'module.waffleiron.spatial_mix.30.norm.bias', 'module.waffleiron.spatial_mix.30.ffn.0.weight', 'module.waffleiron.spatial_mix.30.ffn.0.bias', 'module.waffleiron.spatial_mix.30.ffn.2.weight', 'module.waffleiron.spatial_mix.30.ffn.2.bias', 'module.waffleiron.spatial_mix.31.scale.weight', 'module.waffleiron.spatial_mix.31.norm.weight', 'module.waffleiron.spatial_mix.31.norm.bias', 'module.waffleiron.spatial_mix.31.ffn.0.weight', 'module.waffleiron.spatial_mix.31.ffn.0.bias', 'module.waffleiron.spatial_mix.31.ffn.2.weight', 'module.waffleiron.spatial_mix.31.ffn.2.bias', 'module.waffleiron.spatial_mix.32.scale.weight', 'module.waffleiron.spatial_mix.32.norm.weight', 'module.waffleiron.spatial_mix.32.norm.bias', 'module.waffleiron.spatial_mix.32.ffn.0.weight', 'module.waffleiron.spatial_mix.32.ffn.0.bias', 'module.waffleiron.spatial_mix.32.ffn.2.weight', 'module.waffleiron.spatial_mix.32.ffn.2.bias', 'module.waffleiron.spatial_mix.33.scale.weight', 'module.waffleiron.spatial_mix.33.norm.weight', 'module.waffleiron.spatial_mix.33.norm.bias', 'module.waffleiron.spatial_mix.33.ffn.0.weight', 'module.waffleiron.spatial_mix.33.ffn.0.bias', 'module.waffleiron.spatial_mix.33.ffn.2.weight', 'module.waffleiron.spatial_mix.33.ffn.2.bias', 'module.waffleiron.spatial_mix.34.scale.weight', 'module.waffleiron.spatial_mix.34.norm.weight', 'module.waffleiron.spatial_mix.34.norm.bias', 'module.waffleiron.spatial_mix.34.ffn.0.weight', 'module.waffleiron.spatial_mix.34.ffn.0.bias', 'module.waffleiron.spatial_mix.34.ffn.2.weight', 'module.waffleiron.spatial_mix.34.ffn.2.bias', 'module.waffleiron.spatial_mix.35.scale.weight', 'module.waffleiron.spatial_mix.35.norm.weight', 'module.waffleiron.spatial_mix.35.norm.bias', 'module.waffleiron.spatial_mix.35.ffn.0.weight', 'module.waffleiron.spatial_mix.35.ffn.0.bias', 'module.waffleiron.spatial_mix.35.ffn.2.weight', 'module.waffleiron.spatial_mix.35.ffn.2.bias', 'module.waffleiron.spatial_mix.36.scale.weight', 'module.waffleiron.spatial_mix.36.norm.weight', 'module.waffleiron.spatial_mix.36.norm.bias', 'module.waffleiron.spatial_mix.36.ffn.0.weight', 'module.waffleiron.spatial_mix.36.ffn.0.bias', 'module.waffleiron.spatial_mix.36.ffn.2.weight', 'module.waffleiron.spatial_mix.36.ffn.2.bias', 'module.waffleiron.spatial_mix.37.scale.weight', 'module.waffleiron.spatial_mix.37.norm.weight', 'module.waffleiron.spatial_mix.37.norm.bias', 'module.waffleiron.spatial_mix.37.ffn.0.weight', 'module.waffleiron.spatial_mix.37.ffn.0.bias', 'module.waffleiron.spatial_mix.37.ffn.2.weight', 'module.waffleiron.spatial_mix.37.ffn.2.bias', 'module.waffleiron.spatial_mix.38.scale.weight', 'module.waffleiron.spatial_mix.38.norm.weight', 'module.waffleiron.spatial_mix.38.norm.bias', 'module.waffleiron.spatial_mix.38.ffn.0.weight', 'module.waffleiron.spatial_mix.38.ffn.0.bias', 'module.waffleiron.spatial_mix.38.ffn.2.weight', 'module.waffleiron.spatial_mix.38.ffn.2.bias', 'module.waffleiron.spatial_mix.39.scale.weight', 'module.waffleiron.spatial_mix.39.norm.weight', 'module.waffleiron.spatial_mix.39.norm.bias', 'module.waffleiron.spatial_mix.39.ffn.0.weight', 'module.waffleiron.spatial_mix.39.ffn.0.bias', 'module.waffleiron.spatial_mix.39.ffn.2.weight', 'module.waffleiron.spatial_mix.39.ffn.2.bias', 'module.waffleiron.spatial_mix.40.scale.weight', 'module.waffleiron.spatial_mix.40.norm.weight', 'module.waffleiron.spatial_mix.40.norm.bias', 'module.waffleiron.spatial_mix.40.ffn.0.weight', 'module.waffleiron.spatial_mix.40.ffn.0.bias', 'module.waffleiron.spatial_mix.40.ffn.2.weight', 'module.waffleiron.spatial_mix.40.ffn.2.bias', 'module.waffleiron.spatial_mix.41.scale.weight', 'module.waffleiron.spatial_mix.41.norm.weight', 'module.waffleiron.spatial_mix.41.norm.bias', 'module.waffleiron.spatial_mix.41.ffn.0.weight', 'module.waffleiron.spatial_mix.41.ffn.0.bias', 'module.waffleiron.spatial_mix.41.ffn.2.weight', 'module.waffleiron.spatial_mix.41.ffn.2.bias', 'module.waffleiron.spatial_mix.42.scale.weight', 'module.waffleiron.spatial_mix.42.norm.weight', 'module.waffleiron.spatial_mix.42.norm.bias', 'module.waffleiron.spatial_mix.42.ffn.0.weight', 'module.waffleiron.spatial_mix.42.ffn.0.bias', 'module.waffleiron.spatial_mix.42.ffn.2.weight', 'module.waffleiron.spatial_mix.42.ffn.2.bias', 'module.waffleiron.spatial_mix.43.scale.weight', 'module.waffleiron.spatial_mix.43.norm.weight', 'module.waffleiron.spatial_mix.43.norm.bias', 'module.waffleiron.spatial_mix.43.ffn.0.weight', 'module.waffleiron.spatial_mix.43.ffn.0.bias', 'module.waffleiron.spatial_mix.43.ffn.2.weight', 'module.waffleiron.spatial_mix.43.ffn.2.bias', 'module.waffleiron.spatial_mix.44.scale.weight', 'module.waffleiron.spatial_mix.44.norm.weight', 'module.waffleiron.spatial_mix.44.norm.bias', 'module.waffleiron.spatial_mix.44.ffn.0.weight', 'module.waffleiron.spatial_mix.44.ffn.0.bias', 'module.waffleiron.spatial_mix.44.ffn.2.weight', 'module.waffleiron.spatial_mix.44.ffn.2.bias', 'module.waffleiron.spatial_mix.45.scale.weight', 'module.waffleiron.spatial_mix.45.norm.weight', 'module.waffleiron.spatial_mix.45.norm.bias', 'module.waffleiron.spatial_mix.45.ffn.0.weight', 'module.waffleiron.spatial_mix.45.ffn.0.bias', 'module.waffleiron.spatial_mix.45.ffn.2.weight', 'module.waffleiron.spatial_mix.45.ffn.2.bias', 'module.waffleiron.spatial_mix.46.scale.weight', 'module.waffleiron.spatial_mix.46.norm.weight', 'module.waffleiron.spatial_mix.46.norm.bias', 'module.waffleiron.spatial_mix.46.ffn.0.weight', 'module.waffleiron.spatial_mix.46.ffn.0.bias', 'module.waffleiron.spatial_mix.46.ffn.2.weight', 'module.waffleiron.spatial_mix.46.ffn.2.bias', 'module.waffleiron.spatial_mix.47.scale.weight', 'module.waffleiron.spatial_mix.47.norm.weight', 'module.waffleiron.spatial_mix.47.norm.bias', 'module.waffleiron.spatial_mix.47.ffn.0.weight', 'module.waffleiron.spatial_mix.47.ffn.0.bias', 'module.waffleiron.spatial_mix.47.ffn.2.weight', 'module.waffleiron.spatial_mix.47.ffn.2.bias', 'module.classif.0.weight', 'module.classif.0.bias', 'module.classif.0.running_mean', 'module.classif.0.running_var', 'module.classif.0.num_batches_tracked', 'module.classif.1.weight', 'module.classif.1.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c587871",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ckpt = {}\n",
    "for k in ckpt.keys():\n",
    "    if k.startswith(\"module\"):\n",
    "        if k.startswith(\"module.classif.0\"):\n",
    "            continue\n",
    "        elif k.startswith(\"module.classif.1\"):\n",
    "            new_ckpt[\"classif\" + k[len(\"module.classif.1\") :]] = ckpt[k]\n",
    "        else:\n",
    "            new_ckpt[k[len(\"module.\") :]] = ckpt[k]\n",
    "    else:\n",
    "        new_ckpt[k] = ckpt[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a10e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ckpt.get(\"classif.weight\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca00085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(new_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f2c3d",
   "metadata": {},
   "source": [
    "## Model Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c4ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(\"cuda:0\")\n",
    "model = model.cuda(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e309a941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segmenter(\n",
       "  (embed): Embedding(\n",
       "    (norm): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv1d(5, 768, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Sequential(\n",
       "      (0): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(5, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final): Conv1d(1536, 768, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (waffleiron): WaffleIron(\n",
       "    (channel_mix): ModuleList(\n",
       "      (0): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (1): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (2): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (3): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (4): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (5): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (6): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (7): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (8): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (9): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (10): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (11): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (12): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (13): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (14): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (15): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (16): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (17): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (18): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (19): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (20): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (21): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (22): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (23): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (24): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (25): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (26): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (27): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (28): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (29): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (30): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (31): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (32): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (33): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (34): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (35): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (36): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (37): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (38): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (39): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (40): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (41): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (42): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (43): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (44): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (45): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (46): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (47): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "    (spatial_mix): ModuleList(\n",
       "      (0): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (1): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (2): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (3): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (4): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (5): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (6): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (7): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (8): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (9): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (10): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (11): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (12): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (13): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (14): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (15): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (16): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (17): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (18): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (19): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (20): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (21): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (22): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (23): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (24): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (25): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (26): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (27): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (28): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (29): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (30): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (31): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (32): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (33): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (34): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (35): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (36): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (37): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (38): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (39): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (40): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (41): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (42): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (43): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (44): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (45): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (46): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (47): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classif): Conv1d(768, 16, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10d39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import utils.transforms as tr\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "import os\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "class PCDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rootdir=None,\n",
    "        phase=\"train\",\n",
    "        input_feat=\"intensity\",\n",
    "        voxel_size=0.1,\n",
    "        train_augmentations=None,\n",
    "        dim_proj=[\n",
    "            0,\n",
    "        ],\n",
    "        grids_shape=[(256, 256)],\n",
    "        fov_xyz=(\n",
    "            (-1.0, -1.0, -1.0),\n",
    "            (1.0, 1.0, 1.0),\n",
    "        ),\n",
    "        num_neighbors=16,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Dataset split\n",
    "        self.phase = phase\n",
    "        assert self.phase in [\"train\", \"val\", \"trainval\", \"test\"]\n",
    "\n",
    "        # Root directory of dataset\n",
    "        self.rootdir = rootdir\n",
    "\n",
    "        # Input features to compute for each point\n",
    "        self.input_feat = input_feat\n",
    "\n",
    "        # Downsample input point cloud by small voxelization\n",
    "        self.downsample = tr.Voxelize(\n",
    "            dims=(0, 1, 2),\n",
    "            voxel_size=voxel_size,\n",
    "            random=(self.phase == \"train\" or self.phase == \"trainval\"),\n",
    "        )\n",
    "\n",
    "        # Field of view\n",
    "        assert len(fov_xyz[0]) == len(\n",
    "            fov_xyz[1]\n",
    "        ), \"Min and Max FOV must have the same length.\"\n",
    "        for i, (min, max) in enumerate(zip(*fov_xyz)):\n",
    "            assert (\n",
    "                min < max\n",
    "            ), f\"Field of view: min ({min}) < max ({max}) is expected on dimension {i}.\"\n",
    "        self.fov_xyz = np.concatenate([np.array(f)[None] for f in fov_xyz], axis=0)\n",
    "        self.crop_to_fov = tr.Crop(dims=(0, 1, 2), fov=fov_xyz)\n",
    "\n",
    "        # Grid shape for projection in 2D\n",
    "        assert len(grids_shape) == len(dim_proj)\n",
    "        self.dim_proj = dim_proj\n",
    "        self.grids_shape = [np.array(g) for g in grids_shape]\n",
    "        self.lut_axis_plane = {0: (1, 2), 1: (0, 2), 2: (0, 1)}\n",
    "\n",
    "        # Number of neighbors for embedding layer\n",
    "        assert num_neighbors > 0\n",
    "        self.num_neighbors = num_neighbors\n",
    "\n",
    "        # Train time augmentations\n",
    "        if train_augmentations is not None:\n",
    "            assert self.phase in [\"train\", \"trainval\"]\n",
    "        self.train_augmentations = train_augmentations\n",
    "        \n",
    "        self.list_frames = [\"Lille1_1.ply\"] # ,  \"Lille1_2.ply\",  \"Lille2.ply\",  \"Paris.ply\",\n",
    "        self.mean_int = 18.705505\n",
    "        self.std_int = 23.756725\n",
    "\n",
    "    def get_occupied_2d_cells(self, pc):\n",
    "        \"\"\"Return mapping between 3D point and corresponding 2D cell\"\"\"\n",
    "        cell_ind = []\n",
    "        for dim, grid in zip(self.dim_proj, self.grids_shape):\n",
    "            # Get plane of which to project\n",
    "            dims = self.lut_axis_plane[dim]\n",
    "            # Compute grid resolution\n",
    "            res = (self.fov_xyz[1, dims] - self.fov_xyz[0, dims]) / grid[None]\n",
    "            # Shift and quantize point cloud\n",
    "            pc_quant = ((pc[:, dims] - self.fov_xyz[0, dims]) / res).astype(\"int\")\n",
    "            # Check that the point cloud fits on the grid\n",
    "            min, max = pc_quant.min(0), pc_quant.max(0)\n",
    "            assert min[0] >= 0 and min[1] >= 0, print(\n",
    "                \"Some points are outside the FOV:\", pc[:, :3].min(0), self.fov_xyz\n",
    "            )\n",
    "            assert max[0] < grid[0] and max[1] < grid[1], print(\n",
    "                \"Some points are outside the FOV:\", pc[:, :3].min(0), self.fov_xyz\n",
    "            )\n",
    "            # Transform quantized coordinates to cell indices for projection on 2D plane\n",
    "            temp = pc_quant[:, 0] * grid[1] + pc_quant[:, 1]\n",
    "            cell_ind.append(temp[None])\n",
    "        return np.vstack(cell_ind)\n",
    "\n",
    "    def prepare_input_features(self, pc_orig):\n",
    "        # Concatenate desired input features to coordinates\n",
    "        pc = [pc_orig[:, :3]]  # Initialize with coordinates\n",
    "        for type in self.input_feat:\n",
    "            if type == \"intensity\":\n",
    "                intensity = pc_orig[:, 3:]\n",
    "                intensity = (intensity - self.mean_int) / self.std_int\n",
    "                pc.append(intensity)\n",
    "            elif type == \"height\":\n",
    "                pc.append(pc_orig[:, 2:3])\n",
    "            elif type == \"radius\":\n",
    "                r_xyz = np.linalg.norm(pc_orig[:, :3], axis=1, keepdims=True)\n",
    "                pc.append(r_xyz)\n",
    "            elif type == \"xyz\":\n",
    "                xyz = pc_orig[:, :3]\n",
    "                pc.append(xyz)\n",
    "            elif type == \"constant\":\n",
    "                pc.append(np.ones((pc_orig.shape[0], 1)))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown feature: {type}\")\n",
    "        return np.concatenate(pc, 1)\n",
    "\n",
    "    def load_pc(self, index):\n",
    "        fname = os.path.join(self.rootdir, \"training_10_classes\", self.list_frames[index])\n",
    "        print(\"Loading\")\n",
    "        plydata = PlyData.read(fname)\n",
    "        x = plydata[\"vertex\"].data[\"x\"].astype(np.float32)\n",
    "        y = plydata[\"vertex\"].data[\"y\"].astype(np.float32)\n",
    "        z = plydata[\"vertex\"].data[\"z\"].astype(np.float32)\n",
    "        z = z - 36\n",
    "        reflectance = plydata[\"vertex\"].data[\"reflectance\"].astype(np.float32)\n",
    "        #print(x.shape[0])\n",
    "        feats = np.zeros((x.shape[0], 1))\n",
    "        label = plydata[\"vertex\"].data[\"class\"].astype(np.float32)\n",
    "        #label = label-1\n",
    "        pts = np.concatenate([\n",
    "            np.expand_dims(x,1),\n",
    "            np.expand_dims(y,1),\n",
    "            np.expand_dims(z,1),\n",
    "            np.expand_dims(reflectance,1),\n",
    "            feats,\n",
    "        ], axis=1).astype(np.float32)\n",
    "        print(\"Finished\")\n",
    "        \n",
    "        return pts, np.expand_dims(label,1), self.list_frames[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_frames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load original point cloud\n",
    "        pc_orig, labels_orig, filename = self.load_pc(index)\n",
    "\n",
    "        # Prepare input feature\n",
    "        pc_orig = self.prepare_input_features(pc_orig)\n",
    "\n",
    "        # Voxelization\n",
    "        pc, labels = self.downsample(pc_orig, labels_orig)\n",
    "\n",
    "        # Augment data\n",
    "        if self.train_augmentations is not None:\n",
    "            pc, labels = self.train_augmentations(pc, labels)\n",
    "\n",
    "        # Crop to fov\n",
    "        pc, labels = self.crop_to_fov(pc, labels)\n",
    "\n",
    "        # For each point, get index of corresponding 2D cells on projected grid\n",
    "        cell_ind = self.get_occupied_2d_cells(pc)\n",
    "\n",
    "        # Get neighbors for point embedding layer providing tokens to waffleiron backbone\n",
    "        kdtree = KDTree(pc[:, :3])\n",
    "        assert pc.shape[0] > self.num_neighbors\n",
    "        dist, neighbors_emb = kdtree.query(pc[:, :3], k=self.num_neighbors + 1)\n",
    "\n",
    "        # Nearest neighbor interpolation to undo cropping & voxelisation at validation time\n",
    "        if self.phase in [\"train\", \"trainval\"]:\n",
    "            upsample = np.arange(pc.shape[0])\n",
    "        else:\n",
    "            _, upsample = kdtree.query(pc_orig[:, :3], k=1)\n",
    "\n",
    "        # Output to return\n",
    "        out = (\n",
    "            # Point features\n",
    "            pc[:, 3:].T[None],\n",
    "            # Point labels of original entire point cloud\n",
    "            labels if self.phase in [\"train\", \"trainval\"] else labels_orig,\n",
    "            # Projection 2D -> 3D: index of 2D cells for each point\n",
    "            cell_ind[None],\n",
    "            # Neighborhood for point embedding layer, which provides tokens to waffleiron backbone\n",
    "            neighbors_emb.T[None],\n",
    "            # For interpolation from voxelized & cropped point cloud to original point cloud\n",
    "            upsample,\n",
    "            # Filename of original point cloud\n",
    "            filename,\n",
    "        )\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "337afe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, num_points=None):\n",
    "        self.num_points = num_points\n",
    "        assert num_points is None or num_points > 0\n",
    "\n",
    "    def __call__(self, list_data):\n",
    "\n",
    "        # Extract all data\n",
    "        list_of_data = (list(data) for data in zip(*list_data))\n",
    "        feat, label_orig, cell_ind, neighbors_emb, upsample, filename = list_of_data\n",
    "\n",
    "        # Zero-pad point clouds\n",
    "        Nmax = np.max([f.shape[-1] for f in feat])\n",
    "        if self.num_points is not None:\n",
    "            assert Nmax <= self.num_points\n",
    "        occupied_cells = []\n",
    "        for i in range(len(feat)):\n",
    "            feat[i], neighbors_emb[i], cell_ind[i], temp = zero_pad(\n",
    "                feat[i],\n",
    "                neighbors_emb[i],\n",
    "                cell_ind[i],\n",
    "                Nmax if self.num_points is None else self.num_points,\n",
    "            )\n",
    "            occupied_cells.append(temp)\n",
    "\n",
    "        # Concatenate along batch dimension\n",
    "        feat = torch.from_numpy(np.vstack(feat)).float()  # B x C x Nmax\n",
    "        neighbors_emb = torch.from_numpy(np.vstack(neighbors_emb)).long()  # B x Nmax\n",
    "        cell_ind = torch.from_numpy(\n",
    "            np.vstack(cell_ind)\n",
    "        ).long()  # B x nb_2d_cells x Nmax\n",
    "        occupied_cells = torch.from_numpy(np.vstack(occupied_cells)).float()  # B x Nmax\n",
    "        labels_orig = torch.from_numpy(np.hstack(label_orig)).long()\n",
    "        upsample = [torch.from_numpy(u) for u in upsample]\n",
    "\n",
    "        # Prepare output variables\n",
    "        out = {\n",
    "            \"feat\": feat,\n",
    "            \"neighbors_emb\": neighbors_emb,\n",
    "            \"upsample\": upsample,\n",
    "            \"labels_orig\": labels_orig,\n",
    "            \"cell_ind\": cell_ind,\n",
    "            \"occupied_cells\": occupied_cells,\n",
    "            \"filename\": filename,\n",
    "        }\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1814ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(feat, neighbors_emb, cell_ind, Nmax):\n",
    "    N = feat.shape[-1]\n",
    "    assert N <= Nmax\n",
    "    occupied_cells = np.ones((1, Nmax))\n",
    "    if N < Nmax:\n",
    "        # Zero-pad with null features\n",
    "        feat = np.concatenate((feat, np.zeros((1, feat.shape[1], Nmax - N))), axis=2)\n",
    "        # For zero-padded points, associate last zero-padded points as neighbor\n",
    "        neighbors_emb = np.concatenate(\n",
    "            (\n",
    "                neighbors_emb,\n",
    "                (Nmax - 1) * np.ones((1, neighbors_emb.shape[1], Nmax - N)),\n",
    "            ),\n",
    "            axis=2,\n",
    "        )\n",
    "        # Associate zero-padded points to first 2D cell...\n",
    "        cell_ind = np.concatenate(\n",
    "            (cell_ind, np.zeros((1, cell_ind.shape[1], Nmax - N))), axis=2\n",
    "        )\n",
    "        # ... and at the same time mark zero-padded points as unoccupied\n",
    "        occupied_cells[:, N:] = 0\n",
    "    return feat, neighbors_emb, cell_ind, occupied_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3bad12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "        \"rootdir\": '/root/main/dataset/',\n",
    "        \"input_feat\": [\"xyz\", \"intensity\"],\n",
    "        \"voxel_size\": 0.5,\n",
    "        \"num_neighbors\": 32,\n",
    "        \"dim_proj\": [2, 1, 0],\n",
    "        \"grids_shape\": [[256, 256], [256, 32], [256, 32]],\n",
    "        \"fov_xyz\": [[-64, -64, -10], [64, 64, 10]], # Check here\n",
    "    }\n",
    "\n",
    "train_dataset = PCDataset(\n",
    "        phase=\"val\",\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1dae585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=1,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=Collate(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce92bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Finished\n",
      "tensor([[[ 1.0049e+01,  9.0481e+00,  8.9187e+00,  ...,  1.1089e-01,\n",
      "          -5.5230e+00, -9.5058e-01],\n",
      "         [-5.2929e+01, -5.0746e+01, -5.0893e+01,  ...,  2.8350e+01,\n",
      "           2.8913e+01,  2.8476e+01],\n",
      "         [ 1.1599e+00,  2.5928e+00,  2.2346e+00,  ..., -1.1763e+01,\n",
      "          -1.1004e+01, -5.4609e+00],\n",
      "         ...,\n",
      "         [-1.8681e+02, -1.8602e+02, -1.8686e+02,  ...,  9.5166e+01,\n",
      "           8.8112e+01,  9.3644e+01],\n",
      "         [-4.6611e+00, -5.1680e+00, -5.1689e+00,  ...,  2.5810e+00,\n",
      "           3.6386e+00,  4.3125e+00],\n",
      "         [-6.9176e+00, -6.4271e+00, -6.2402e+00,  ...,  1.7132e+01,\n",
      "           1.5623e+01,  1.1076e+01]]], device='cuda:0')\n",
      "torch.Size([1, 768, 1878])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HyperLiDAR/models/waffleiron/helper_projection.py:32: UserWarning: scatter_reduce() is in beta and the API may change at any time. (Triggered internally at ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:1615.)\n",
      "  include_self=False,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-9.1422e+01, -1.0900e+02, -9.4093e+01,  ...,  4.6501e-02,\n",
      "           2.4376e+01,  3.8825e+01],\n",
      "         [-2.6143e+01, -2.7419e+01, -2.9566e+01,  ..., -9.0793e+01,\n",
      "          -1.6471e+02, -1.1865e+02],\n",
      "         [-2.6571e+01, -5.5471e+00, -2.2792e+01,  ...,  5.5333e+01,\n",
      "           8.2744e+01,  7.2795e+01],\n",
      "         ...,\n",
      "         [ 2.5103e+02,  2.3928e+02,  2.4985e+02,  ..., -1.4999e+02,\n",
      "          -1.3057e+02, -1.5791e+02],\n",
      "         [-9.5130e+01, -9.2589e+01, -9.5435e+01,  ..., -1.6039e+01,\n",
      "           2.1876e+01, -8.9950e+00],\n",
      "         [ 6.0435e+01,  5.5213e+01,  6.2486e+01,  ..., -4.9079e+01,\n",
      "          -3.4421e+01, -5.5955e+01]]], device='cuda:0')\n",
      "torch.Size([1, 768, 1878])\n"
     ]
    }
   ],
   "source": [
    "for it, batch in enumerate(train_loader):\n",
    "    \n",
    "    if it == 0:\n",
    "\n",
    "        # Network inputs\n",
    "        #print(batch[\"upsample\"])\n",
    "        feat = batch[\"feat\"].cuda(0, non_blocking=True)\n",
    "        labels = batch[\"labels_orig\"].cuda(0, non_blocking=True)\n",
    "        batch[\"upsample\"] = [\n",
    "            up.cuda(0, non_blocking=True) for up in batch[\"upsample\"]\n",
    "        ]\n",
    "        cell_ind = batch[\"cell_ind\"].cuda(0, non_blocking=True)\n",
    "        occupied_cell = batch[\"occupied_cells\"].cuda(0, non_blocking=True)\n",
    "        neighbors_emb = batch[\"neighbors_emb\"].cuda(0, non_blocking=True)\n",
    "        net_inputs = (feat, cell_ind, occupied_cell, neighbors_emb)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(*net_inputs)\n",
    "        \n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41f2e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, embed, tokens = out[0], out[1], out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6999c981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30033430, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55755ad",
   "metadata": {},
   "source": [
    "## Out check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ffb61411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([1868, 1868, 1868,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Voxels to points\n",
    "out_upsample = []\n",
    "for id_b, closest_point in enumerate(batch[\"upsample\"]):\n",
    "    print(id_b)\n",
    "    print(closest_point)\n",
    "    temp = out[id_b, :, closest_point]\n",
    "    out_upsample.append(temp.T)\n",
    "out_2 = torch.cat(out_upsample, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "25ee03ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 390.9475, -348.0847,  -87.7982,  ...,   -0.9795,  297.8709,\n",
       "           -4.1664],\n",
       "        [ 390.9475, -348.0847,  -87.7982,  ...,   -0.9795,  297.8709,\n",
       "           -4.1664],\n",
       "        [ 390.9475, -348.0847,  -87.7982,  ...,   -0.9795,  297.8709,\n",
       "           -4.1664],\n",
       "        ...,\n",
       "        [-310.8869,  278.1849, -329.1114,  ..., -101.7140,  768.8454,\n",
       "         -140.5068],\n",
       "        [-310.8869,  278.1849, -329.1114,  ..., -101.7140,  768.8454,\n",
       "         -140.5068],\n",
       "        [-310.8869,  278.1849, -329.1114,  ..., -101.7140,  768.8454,\n",
       "         -140.5068]], device='cuda:0')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dc098256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30033430, 16])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "32f7a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    nb_class = out_2.shape[1]\n",
    "    pred_label = out_2.max(1)[1] + 1\n",
    "    labels = labels[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "80368336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30033430])\n",
      "torch.Size([30033430])\n"
     ]
    }
   ],
   "source": [
    "print(pred_label.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f283203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3a5cc781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8674f234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([       0,  2680048,  2554278,        0,   492562,   582521, 22980276,\n",
      "               0,        0,   530583,      273,    85557,        0,        0,\n",
      "               0,   127332], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.bincount(pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa3588",
   "metadata": {},
   "source": [
    "### Npm3D\n",
    "\n",
    "0 unclassified\n",
    "1 ground\n",
    "2 building\n",
    "3 pole - road sign - traffic light\n",
    "4 bollard - small pole\n",
    "5 trash can\n",
    "6 barrier\n",
    "7 pedestrian\n",
    "8 car\n",
    "9 natural - vegetation\n",
    "\n",
    "### Nuscenes\n",
    "\n",
    "0: 'noise'\n",
    "1: 'barrier'\n",
    "2: 'bicycle'\n",
    "3: 'bus'\n",
    "4: 'car'\n",
    "5: 'construction_vehicle'\n",
    "6: 'motorcycle'\n",
    "7: 'pedestrian'\n",
    "8: 'traffic_cone'\n",
    "9: 'trailer'\n",
    "10: 'truck'\n",
    "11: 'driveable_surface'\n",
    "12: 'other_flat'\n",
    "13: 'sidewalk'\n",
    "14: 'terrain'\n",
    "15: 'manmade'\n",
    "16: 'vegetation'\n",
    "\n",
    "0 - 0\n",
    "1 - 11 or 12 or 13 or 14\n",
    "2 - IGNORE\n",
    "3 - 8\n",
    "4 - IGNORE\n",
    "5 - IGNORE\n",
    "6 - 1\n",
    "7 - 7\n",
    "8 - 2 or 3 or 4 or 5 or 6 or 9 or 10\n",
    "9 - 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ed8ba850",
   "metadata": {},
   "outputs": [],
   "source": [
    "change = {1:6, 2:8, 3:8, 4:8, 5:8, 6:8, 7:7, 8:3, 9:9, 10:8, 11:1, 12:1, 13:1, 14:1, 15:2, 16:9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c9746743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything is being classified as a motorcycle..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "fed8da73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 16/16 [00:00<00:00, 29879.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Create a lookup table (assuming tensor values are in a known range)\n",
    "max_key = max(change.keys())  # Find the largest key in the dictionary\n",
    "lookup_table = torch.zeros(max_key + 1, dtype=torch.long, device=torch.device('cuda'))  # Initialize the lookup table\n",
    "\n",
    "# Populate the lookup table with the dictionary values\n",
    "for key, value in tqdm(change.items()):\n",
    "    lookup_table[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a58d61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the lookup table to map the original tensor\n",
    "mapped_tensor = lookup_table[pred_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "920c353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6,  ..., 8, 8, 8], device='cuda:0')"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "644996dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0')"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "43df19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of values you want to exclude\n",
    "from utils.metrics import overall_accuracy, fast_hist\n",
    "\n",
    "exclude_labels = torch.tensor([0, 2, 4, 5], device=torch.device('cuda'))\n",
    "\n",
    "where = ~torch.isin(labels, exclude_labels)\n",
    "confusion_matrix = fast_hist(\n",
    "    mapped_tensor[where], labels[where], 10\n",
    ") # pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "12fa974a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[       0,        0,        0,        0,        0,        0,        0,\n",
       "                0,        0,        0],\n",
       "        [       0,    68477,    17812,        0,        0,        0,  1262871,\n",
       "                0, 15809259,   304449],\n",
       "        [       0,        0,        0,        0,        0,        0,        0,\n",
       "                0,        0,        0],\n",
       "        [       0,        0,        0,        0,        0,        0,     8931,\n",
       "                0,   153778,     4413],\n",
       "        [       0,        0,        0,        0,        0,        0,        0,\n",
       "                0,        0,        0],\n",
       "        [       0,        0,        0,        0,        0,        0,        0,\n",
       "                0,        0,        0],\n",
       "        [       0,        0,        0,        0,        0,        0,    32284,\n",
       "                0,  1168675,     9569],\n",
       "        [       0,        0,        0,        0,        0,        0,     3245,\n",
       "                0,    11429,     1616],\n",
       "        [       0,    10279,        0,        0,        0,        0,   228988,\n",
       "                0,  1009710,    42209],\n",
       "        [       0,      681,        0,        0,        0,        0,     4357,\n",
       "                0,  2166021,    17762]], device='cuda:0')"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix\n",
    "# Label row Pred Columne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "61cfda4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = confusion_matrix.sum(dim=1, keepdim=True)  # Sum along rows\n",
    "confusion_matrix_normalized = confusion_matrix / torch.clamp(row_sums, min=1e-6)  # Avoid division by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "dade0273",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_normalized = confusion_matrix / torch.sum(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "958e9a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Option 1: Use matplotlib to visualize the matrix as a heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(confusion_matrix_normalized.cpu(), cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()  # Add color bar to interpret the values\n",
    "plt.title('Confusion Matrix (fast_hist)')\n",
    "plt.savefig('fast_hist_heatmap.png')  # Save the heatmap as an image\n",
    "plt.show()  # Display the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "94bdbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0ad62e",
   "metadata": {},
   "source": [
    "## Embed check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dcf5321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 1878])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36f5b7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30033430, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voxels to points of embed? # HAs very high dimensionality on all points --> Reduce to somesubsample...\n",
    "embed_upsample = []\n",
    "for id_b, closest_point in enumerate(batch[\"upsample\"]):\n",
    "    #print(id_b) # Id of the batch\n",
    "    #print(closest_point)\n",
    "    #print(closest_point.shape)\n",
    "    batch_size = 100\n",
    "    num_crops = closest_point.shape[0] // batch_size\n",
    "    for i in range(num_crops):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        temp = embed[id_b, :, start:end]\n",
    "        print(labels[start:end].T)\n",
    "        embed_upsample.append(temp.T)\n",
    "        print(embed_upsample)\n",
    "        x = input(\"Enter\")\n",
    "#embed_2 = torch.cat(embed_upsample, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d694cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
