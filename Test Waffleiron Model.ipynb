{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd417ca",
   "metadata": {},
   "source": [
    "# Test WaffleIron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afc500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch.scatter_reduce for 3D to 2D projection.\n",
      "Using torch.scatter_reduce for 3D to 2D projection.\n"
     ]
    }
   ],
   "source": [
    "from models.waffleiron.segmenter import Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12df3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Segmenter(\n",
    "    input_channels=5,\n",
    "    feat_channels=768,\n",
    "    depth=48,\n",
    "    grid_shape=[[256, 256], [256, 32], [256, 32]],\n",
    "    nb_class=16, # class for prediction\n",
    "    #drop_path_prob=config[\"waffleiron\"][\"drop_path\"],\n",
    "    layer_norm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff7e82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load pretrained model\n",
    "ckpt = torch.load('./saved_models/ckpt_last_scalr.pth', map_location=\"cuda:0\")\n",
    "ckpt = ckpt[\"net\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4933ff55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['module.embed.norm.weight', 'module.embed.norm.bias', 'module.embed.norm.running_mean', 'module.embed.norm.running_var', 'module.embed.norm.num_batches_tracked', 'module.embed.conv1.weight', 'module.embed.conv1.bias', 'module.embed.conv2.0.weight', 'module.embed.conv2.0.bias', 'module.embed.conv2.0.running_mean', 'module.embed.conv2.0.running_var', 'module.embed.conv2.0.num_batches_tracked', 'module.embed.conv2.1.weight', 'module.embed.conv2.2.weight', 'module.embed.conv2.2.bias', 'module.embed.conv2.2.running_mean', 'module.embed.conv2.2.running_var', 'module.embed.conv2.2.num_batches_tracked', 'module.embed.conv2.4.weight', 'module.embed.final.weight', 'module.embed.final.bias', 'module.waffleiron.channel_mix.0.scale.weight', 'module.waffleiron.channel_mix.0.norm.weight', 'module.waffleiron.channel_mix.0.norm.bias', 'module.waffleiron.channel_mix.0.mlp.0.weight', 'module.waffleiron.channel_mix.0.mlp.0.bias', 'module.waffleiron.channel_mix.0.mlp.2.weight', 'module.waffleiron.channel_mix.0.mlp.2.bias', 'module.waffleiron.channel_mix.1.scale.weight', 'module.waffleiron.channel_mix.1.norm.weight', 'module.waffleiron.channel_mix.1.norm.bias', 'module.waffleiron.channel_mix.1.mlp.0.weight', 'module.waffleiron.channel_mix.1.mlp.0.bias', 'module.waffleiron.channel_mix.1.mlp.2.weight', 'module.waffleiron.channel_mix.1.mlp.2.bias', 'module.waffleiron.channel_mix.2.scale.weight', 'module.waffleiron.channel_mix.2.norm.weight', 'module.waffleiron.channel_mix.2.norm.bias', 'module.waffleiron.channel_mix.2.mlp.0.weight', 'module.waffleiron.channel_mix.2.mlp.0.bias', 'module.waffleiron.channel_mix.2.mlp.2.weight', 'module.waffleiron.channel_mix.2.mlp.2.bias', 'module.waffleiron.channel_mix.3.scale.weight', 'module.waffleiron.channel_mix.3.norm.weight', 'module.waffleiron.channel_mix.3.norm.bias', 'module.waffleiron.channel_mix.3.mlp.0.weight', 'module.waffleiron.channel_mix.3.mlp.0.bias', 'module.waffleiron.channel_mix.3.mlp.2.weight', 'module.waffleiron.channel_mix.3.mlp.2.bias', 'module.waffleiron.channel_mix.4.scale.weight', 'module.waffleiron.channel_mix.4.norm.weight', 'module.waffleiron.channel_mix.4.norm.bias', 'module.waffleiron.channel_mix.4.mlp.0.weight', 'module.waffleiron.channel_mix.4.mlp.0.bias', 'module.waffleiron.channel_mix.4.mlp.2.weight', 'module.waffleiron.channel_mix.4.mlp.2.bias', 'module.waffleiron.channel_mix.5.scale.weight', 'module.waffleiron.channel_mix.5.norm.weight', 'module.waffleiron.channel_mix.5.norm.bias', 'module.waffleiron.channel_mix.5.mlp.0.weight', 'module.waffleiron.channel_mix.5.mlp.0.bias', 'module.waffleiron.channel_mix.5.mlp.2.weight', 'module.waffleiron.channel_mix.5.mlp.2.bias', 'module.waffleiron.channel_mix.6.scale.weight', 'module.waffleiron.channel_mix.6.norm.weight', 'module.waffleiron.channel_mix.6.norm.bias', 'module.waffleiron.channel_mix.6.mlp.0.weight', 'module.waffleiron.channel_mix.6.mlp.0.bias', 'module.waffleiron.channel_mix.6.mlp.2.weight', 'module.waffleiron.channel_mix.6.mlp.2.bias', 'module.waffleiron.channel_mix.7.scale.weight', 'module.waffleiron.channel_mix.7.norm.weight', 'module.waffleiron.channel_mix.7.norm.bias', 'module.waffleiron.channel_mix.7.mlp.0.weight', 'module.waffleiron.channel_mix.7.mlp.0.bias', 'module.waffleiron.channel_mix.7.mlp.2.weight', 'module.waffleiron.channel_mix.7.mlp.2.bias', 'module.waffleiron.channel_mix.8.scale.weight', 'module.waffleiron.channel_mix.8.norm.weight', 'module.waffleiron.channel_mix.8.norm.bias', 'module.waffleiron.channel_mix.8.mlp.0.weight', 'module.waffleiron.channel_mix.8.mlp.0.bias', 'module.waffleiron.channel_mix.8.mlp.2.weight', 'module.waffleiron.channel_mix.8.mlp.2.bias', 'module.waffleiron.channel_mix.9.scale.weight', 'module.waffleiron.channel_mix.9.norm.weight', 'module.waffleiron.channel_mix.9.norm.bias', 'module.waffleiron.channel_mix.9.mlp.0.weight', 'module.waffleiron.channel_mix.9.mlp.0.bias', 'module.waffleiron.channel_mix.9.mlp.2.weight', 'module.waffleiron.channel_mix.9.mlp.2.bias', 'module.waffleiron.channel_mix.10.scale.weight', 'module.waffleiron.channel_mix.10.norm.weight', 'module.waffleiron.channel_mix.10.norm.bias', 'module.waffleiron.channel_mix.10.mlp.0.weight', 'module.waffleiron.channel_mix.10.mlp.0.bias', 'module.waffleiron.channel_mix.10.mlp.2.weight', 'module.waffleiron.channel_mix.10.mlp.2.bias', 'module.waffleiron.channel_mix.11.scale.weight', 'module.waffleiron.channel_mix.11.norm.weight', 'module.waffleiron.channel_mix.11.norm.bias', 'module.waffleiron.channel_mix.11.mlp.0.weight', 'module.waffleiron.channel_mix.11.mlp.0.bias', 'module.waffleiron.channel_mix.11.mlp.2.weight', 'module.waffleiron.channel_mix.11.mlp.2.bias', 'module.waffleiron.channel_mix.12.scale.weight', 'module.waffleiron.channel_mix.12.norm.weight', 'module.waffleiron.channel_mix.12.norm.bias', 'module.waffleiron.channel_mix.12.mlp.0.weight', 'module.waffleiron.channel_mix.12.mlp.0.bias', 'module.waffleiron.channel_mix.12.mlp.2.weight', 'module.waffleiron.channel_mix.12.mlp.2.bias', 'module.waffleiron.channel_mix.13.scale.weight', 'module.waffleiron.channel_mix.13.norm.weight', 'module.waffleiron.channel_mix.13.norm.bias', 'module.waffleiron.channel_mix.13.mlp.0.weight', 'module.waffleiron.channel_mix.13.mlp.0.bias', 'module.waffleiron.channel_mix.13.mlp.2.weight', 'module.waffleiron.channel_mix.13.mlp.2.bias', 'module.waffleiron.channel_mix.14.scale.weight', 'module.waffleiron.channel_mix.14.norm.weight', 'module.waffleiron.channel_mix.14.norm.bias', 'module.waffleiron.channel_mix.14.mlp.0.weight', 'module.waffleiron.channel_mix.14.mlp.0.bias', 'module.waffleiron.channel_mix.14.mlp.2.weight', 'module.waffleiron.channel_mix.14.mlp.2.bias', 'module.waffleiron.channel_mix.15.scale.weight', 'module.waffleiron.channel_mix.15.norm.weight', 'module.waffleiron.channel_mix.15.norm.bias', 'module.waffleiron.channel_mix.15.mlp.0.weight', 'module.waffleiron.channel_mix.15.mlp.0.bias', 'module.waffleiron.channel_mix.15.mlp.2.weight', 'module.waffleiron.channel_mix.15.mlp.2.bias', 'module.waffleiron.channel_mix.16.scale.weight', 'module.waffleiron.channel_mix.16.norm.weight', 'module.waffleiron.channel_mix.16.norm.bias', 'module.waffleiron.channel_mix.16.mlp.0.weight', 'module.waffleiron.channel_mix.16.mlp.0.bias', 'module.waffleiron.channel_mix.16.mlp.2.weight', 'module.waffleiron.channel_mix.16.mlp.2.bias', 'module.waffleiron.channel_mix.17.scale.weight', 'module.waffleiron.channel_mix.17.norm.weight', 'module.waffleiron.channel_mix.17.norm.bias', 'module.waffleiron.channel_mix.17.mlp.0.weight', 'module.waffleiron.channel_mix.17.mlp.0.bias', 'module.waffleiron.channel_mix.17.mlp.2.weight', 'module.waffleiron.channel_mix.17.mlp.2.bias', 'module.waffleiron.channel_mix.18.scale.weight', 'module.waffleiron.channel_mix.18.norm.weight', 'module.waffleiron.channel_mix.18.norm.bias', 'module.waffleiron.channel_mix.18.mlp.0.weight', 'module.waffleiron.channel_mix.18.mlp.0.bias', 'module.waffleiron.channel_mix.18.mlp.2.weight', 'module.waffleiron.channel_mix.18.mlp.2.bias', 'module.waffleiron.channel_mix.19.scale.weight', 'module.waffleiron.channel_mix.19.norm.weight', 'module.waffleiron.channel_mix.19.norm.bias', 'module.waffleiron.channel_mix.19.mlp.0.weight', 'module.waffleiron.channel_mix.19.mlp.0.bias', 'module.waffleiron.channel_mix.19.mlp.2.weight', 'module.waffleiron.channel_mix.19.mlp.2.bias', 'module.waffleiron.channel_mix.20.scale.weight', 'module.waffleiron.channel_mix.20.norm.weight', 'module.waffleiron.channel_mix.20.norm.bias', 'module.waffleiron.channel_mix.20.mlp.0.weight', 'module.waffleiron.channel_mix.20.mlp.0.bias', 'module.waffleiron.channel_mix.20.mlp.2.weight', 'module.waffleiron.channel_mix.20.mlp.2.bias', 'module.waffleiron.channel_mix.21.scale.weight', 'module.waffleiron.channel_mix.21.norm.weight', 'module.waffleiron.channel_mix.21.norm.bias', 'module.waffleiron.channel_mix.21.mlp.0.weight', 'module.waffleiron.channel_mix.21.mlp.0.bias', 'module.waffleiron.channel_mix.21.mlp.2.weight', 'module.waffleiron.channel_mix.21.mlp.2.bias', 'module.waffleiron.channel_mix.22.scale.weight', 'module.waffleiron.channel_mix.22.norm.weight', 'module.waffleiron.channel_mix.22.norm.bias', 'module.waffleiron.channel_mix.22.mlp.0.weight', 'module.waffleiron.channel_mix.22.mlp.0.bias', 'module.waffleiron.channel_mix.22.mlp.2.weight', 'module.waffleiron.channel_mix.22.mlp.2.bias', 'module.waffleiron.channel_mix.23.scale.weight', 'module.waffleiron.channel_mix.23.norm.weight', 'module.waffleiron.channel_mix.23.norm.bias', 'module.waffleiron.channel_mix.23.mlp.0.weight', 'module.waffleiron.channel_mix.23.mlp.0.bias', 'module.waffleiron.channel_mix.23.mlp.2.weight', 'module.waffleiron.channel_mix.23.mlp.2.bias', 'module.waffleiron.channel_mix.24.scale.weight', 'module.waffleiron.channel_mix.24.norm.weight', 'module.waffleiron.channel_mix.24.norm.bias', 'module.waffleiron.channel_mix.24.mlp.0.weight', 'module.waffleiron.channel_mix.24.mlp.0.bias', 'module.waffleiron.channel_mix.24.mlp.2.weight', 'module.waffleiron.channel_mix.24.mlp.2.bias', 'module.waffleiron.channel_mix.25.scale.weight', 'module.waffleiron.channel_mix.25.norm.weight', 'module.waffleiron.channel_mix.25.norm.bias', 'module.waffleiron.channel_mix.25.mlp.0.weight', 'module.waffleiron.channel_mix.25.mlp.0.bias', 'module.waffleiron.channel_mix.25.mlp.2.weight', 'module.waffleiron.channel_mix.25.mlp.2.bias', 'module.waffleiron.channel_mix.26.scale.weight', 'module.waffleiron.channel_mix.26.norm.weight', 'module.waffleiron.channel_mix.26.norm.bias', 'module.waffleiron.channel_mix.26.mlp.0.weight', 'module.waffleiron.channel_mix.26.mlp.0.bias', 'module.waffleiron.channel_mix.26.mlp.2.weight', 'module.waffleiron.channel_mix.26.mlp.2.bias', 'module.waffleiron.channel_mix.27.scale.weight', 'module.waffleiron.channel_mix.27.norm.weight', 'module.waffleiron.channel_mix.27.norm.bias', 'module.waffleiron.channel_mix.27.mlp.0.weight', 'module.waffleiron.channel_mix.27.mlp.0.bias', 'module.waffleiron.channel_mix.27.mlp.2.weight', 'module.waffleiron.channel_mix.27.mlp.2.bias', 'module.waffleiron.channel_mix.28.scale.weight', 'module.waffleiron.channel_mix.28.norm.weight', 'module.waffleiron.channel_mix.28.norm.bias', 'module.waffleiron.channel_mix.28.mlp.0.weight', 'module.waffleiron.channel_mix.28.mlp.0.bias', 'module.waffleiron.channel_mix.28.mlp.2.weight', 'module.waffleiron.channel_mix.28.mlp.2.bias', 'module.waffleiron.channel_mix.29.scale.weight', 'module.waffleiron.channel_mix.29.norm.weight', 'module.waffleiron.channel_mix.29.norm.bias', 'module.waffleiron.channel_mix.29.mlp.0.weight', 'module.waffleiron.channel_mix.29.mlp.0.bias', 'module.waffleiron.channel_mix.29.mlp.2.weight', 'module.waffleiron.channel_mix.29.mlp.2.bias', 'module.waffleiron.channel_mix.30.scale.weight', 'module.waffleiron.channel_mix.30.norm.weight', 'module.waffleiron.channel_mix.30.norm.bias', 'module.waffleiron.channel_mix.30.mlp.0.weight', 'module.waffleiron.channel_mix.30.mlp.0.bias', 'module.waffleiron.channel_mix.30.mlp.2.weight', 'module.waffleiron.channel_mix.30.mlp.2.bias', 'module.waffleiron.channel_mix.31.scale.weight', 'module.waffleiron.channel_mix.31.norm.weight', 'module.waffleiron.channel_mix.31.norm.bias', 'module.waffleiron.channel_mix.31.mlp.0.weight', 'module.waffleiron.channel_mix.31.mlp.0.bias', 'module.waffleiron.channel_mix.31.mlp.2.weight', 'module.waffleiron.channel_mix.31.mlp.2.bias', 'module.waffleiron.channel_mix.32.scale.weight', 'module.waffleiron.channel_mix.32.norm.weight', 'module.waffleiron.channel_mix.32.norm.bias', 'module.waffleiron.channel_mix.32.mlp.0.weight', 'module.waffleiron.channel_mix.32.mlp.0.bias', 'module.waffleiron.channel_mix.32.mlp.2.weight', 'module.waffleiron.channel_mix.32.mlp.2.bias', 'module.waffleiron.channel_mix.33.scale.weight', 'module.waffleiron.channel_mix.33.norm.weight', 'module.waffleiron.channel_mix.33.norm.bias', 'module.waffleiron.channel_mix.33.mlp.0.weight', 'module.waffleiron.channel_mix.33.mlp.0.bias', 'module.waffleiron.channel_mix.33.mlp.2.weight', 'module.waffleiron.channel_mix.33.mlp.2.bias', 'module.waffleiron.channel_mix.34.scale.weight', 'module.waffleiron.channel_mix.34.norm.weight', 'module.waffleiron.channel_mix.34.norm.bias', 'module.waffleiron.channel_mix.34.mlp.0.weight', 'module.waffleiron.channel_mix.34.mlp.0.bias', 'module.waffleiron.channel_mix.34.mlp.2.weight', 'module.waffleiron.channel_mix.34.mlp.2.bias', 'module.waffleiron.channel_mix.35.scale.weight', 'module.waffleiron.channel_mix.35.norm.weight', 'module.waffleiron.channel_mix.35.norm.bias', 'module.waffleiron.channel_mix.35.mlp.0.weight', 'module.waffleiron.channel_mix.35.mlp.0.bias', 'module.waffleiron.channel_mix.35.mlp.2.weight', 'module.waffleiron.channel_mix.35.mlp.2.bias', 'module.waffleiron.channel_mix.36.scale.weight', 'module.waffleiron.channel_mix.36.norm.weight', 'module.waffleiron.channel_mix.36.norm.bias', 'module.waffleiron.channel_mix.36.mlp.0.weight', 'module.waffleiron.channel_mix.36.mlp.0.bias', 'module.waffleiron.channel_mix.36.mlp.2.weight', 'module.waffleiron.channel_mix.36.mlp.2.bias', 'module.waffleiron.channel_mix.37.scale.weight', 'module.waffleiron.channel_mix.37.norm.weight', 'module.waffleiron.channel_mix.37.norm.bias', 'module.waffleiron.channel_mix.37.mlp.0.weight', 'module.waffleiron.channel_mix.37.mlp.0.bias', 'module.waffleiron.channel_mix.37.mlp.2.weight', 'module.waffleiron.channel_mix.37.mlp.2.bias', 'module.waffleiron.channel_mix.38.scale.weight', 'module.waffleiron.channel_mix.38.norm.weight', 'module.waffleiron.channel_mix.38.norm.bias', 'module.waffleiron.channel_mix.38.mlp.0.weight', 'module.waffleiron.channel_mix.38.mlp.0.bias', 'module.waffleiron.channel_mix.38.mlp.2.weight', 'module.waffleiron.channel_mix.38.mlp.2.bias', 'module.waffleiron.channel_mix.39.scale.weight', 'module.waffleiron.channel_mix.39.norm.weight', 'module.waffleiron.channel_mix.39.norm.bias', 'module.waffleiron.channel_mix.39.mlp.0.weight', 'module.waffleiron.channel_mix.39.mlp.0.bias', 'module.waffleiron.channel_mix.39.mlp.2.weight', 'module.waffleiron.channel_mix.39.mlp.2.bias', 'module.waffleiron.channel_mix.40.scale.weight', 'module.waffleiron.channel_mix.40.norm.weight', 'module.waffleiron.channel_mix.40.norm.bias', 'module.waffleiron.channel_mix.40.mlp.0.weight', 'module.waffleiron.channel_mix.40.mlp.0.bias', 'module.waffleiron.channel_mix.40.mlp.2.weight', 'module.waffleiron.channel_mix.40.mlp.2.bias', 'module.waffleiron.channel_mix.41.scale.weight', 'module.waffleiron.channel_mix.41.norm.weight', 'module.waffleiron.channel_mix.41.norm.bias', 'module.waffleiron.channel_mix.41.mlp.0.weight', 'module.waffleiron.channel_mix.41.mlp.0.bias', 'module.waffleiron.channel_mix.41.mlp.2.weight', 'module.waffleiron.channel_mix.41.mlp.2.bias', 'module.waffleiron.channel_mix.42.scale.weight', 'module.waffleiron.channel_mix.42.norm.weight', 'module.waffleiron.channel_mix.42.norm.bias', 'module.waffleiron.channel_mix.42.mlp.0.weight', 'module.waffleiron.channel_mix.42.mlp.0.bias', 'module.waffleiron.channel_mix.42.mlp.2.weight', 'module.waffleiron.channel_mix.42.mlp.2.bias', 'module.waffleiron.channel_mix.43.scale.weight', 'module.waffleiron.channel_mix.43.norm.weight', 'module.waffleiron.channel_mix.43.norm.bias', 'module.waffleiron.channel_mix.43.mlp.0.weight', 'module.waffleiron.channel_mix.43.mlp.0.bias', 'module.waffleiron.channel_mix.43.mlp.2.weight', 'module.waffleiron.channel_mix.43.mlp.2.bias', 'module.waffleiron.channel_mix.44.scale.weight', 'module.waffleiron.channel_mix.44.norm.weight', 'module.waffleiron.channel_mix.44.norm.bias', 'module.waffleiron.channel_mix.44.mlp.0.weight', 'module.waffleiron.channel_mix.44.mlp.0.bias', 'module.waffleiron.channel_mix.44.mlp.2.weight', 'module.waffleiron.channel_mix.44.mlp.2.bias', 'module.waffleiron.channel_mix.45.scale.weight', 'module.waffleiron.channel_mix.45.norm.weight', 'module.waffleiron.channel_mix.45.norm.bias', 'module.waffleiron.channel_mix.45.mlp.0.weight', 'module.waffleiron.channel_mix.45.mlp.0.bias', 'module.waffleiron.channel_mix.45.mlp.2.weight', 'module.waffleiron.channel_mix.45.mlp.2.bias', 'module.waffleiron.channel_mix.46.scale.weight', 'module.waffleiron.channel_mix.46.norm.weight', 'module.waffleiron.channel_mix.46.norm.bias', 'module.waffleiron.channel_mix.46.mlp.0.weight', 'module.waffleiron.channel_mix.46.mlp.0.bias', 'module.waffleiron.channel_mix.46.mlp.2.weight', 'module.waffleiron.channel_mix.46.mlp.2.bias', 'module.waffleiron.channel_mix.47.scale.weight', 'module.waffleiron.channel_mix.47.norm.weight', 'module.waffleiron.channel_mix.47.norm.bias', 'module.waffleiron.channel_mix.47.mlp.0.weight', 'module.waffleiron.channel_mix.47.mlp.0.bias', 'module.waffleiron.channel_mix.47.mlp.2.weight', 'module.waffleiron.channel_mix.47.mlp.2.bias', 'module.waffleiron.spatial_mix.0.scale.weight', 'module.waffleiron.spatial_mix.0.norm.weight', 'module.waffleiron.spatial_mix.0.norm.bias', 'module.waffleiron.spatial_mix.0.ffn.0.weight', 'module.waffleiron.spatial_mix.0.ffn.0.bias', 'module.waffleiron.spatial_mix.0.ffn.2.weight', 'module.waffleiron.spatial_mix.0.ffn.2.bias', 'module.waffleiron.spatial_mix.1.scale.weight', 'module.waffleiron.spatial_mix.1.norm.weight', 'module.waffleiron.spatial_mix.1.norm.bias', 'module.waffleiron.spatial_mix.1.ffn.0.weight', 'module.waffleiron.spatial_mix.1.ffn.0.bias', 'module.waffleiron.spatial_mix.1.ffn.2.weight', 'module.waffleiron.spatial_mix.1.ffn.2.bias', 'module.waffleiron.spatial_mix.2.scale.weight', 'module.waffleiron.spatial_mix.2.norm.weight', 'module.waffleiron.spatial_mix.2.norm.bias', 'module.waffleiron.spatial_mix.2.ffn.0.weight', 'module.waffleiron.spatial_mix.2.ffn.0.bias', 'module.waffleiron.spatial_mix.2.ffn.2.weight', 'module.waffleiron.spatial_mix.2.ffn.2.bias', 'module.waffleiron.spatial_mix.3.scale.weight', 'module.waffleiron.spatial_mix.3.norm.weight', 'module.waffleiron.spatial_mix.3.norm.bias', 'module.waffleiron.spatial_mix.3.ffn.0.weight', 'module.waffleiron.spatial_mix.3.ffn.0.bias', 'module.waffleiron.spatial_mix.3.ffn.2.weight', 'module.waffleiron.spatial_mix.3.ffn.2.bias', 'module.waffleiron.spatial_mix.4.scale.weight', 'module.waffleiron.spatial_mix.4.norm.weight', 'module.waffleiron.spatial_mix.4.norm.bias', 'module.waffleiron.spatial_mix.4.ffn.0.weight', 'module.waffleiron.spatial_mix.4.ffn.0.bias', 'module.waffleiron.spatial_mix.4.ffn.2.weight', 'module.waffleiron.spatial_mix.4.ffn.2.bias', 'module.waffleiron.spatial_mix.5.scale.weight', 'module.waffleiron.spatial_mix.5.norm.weight', 'module.waffleiron.spatial_mix.5.norm.bias', 'module.waffleiron.spatial_mix.5.ffn.0.weight', 'module.waffleiron.spatial_mix.5.ffn.0.bias', 'module.waffleiron.spatial_mix.5.ffn.2.weight', 'module.waffleiron.spatial_mix.5.ffn.2.bias', 'module.waffleiron.spatial_mix.6.scale.weight', 'module.waffleiron.spatial_mix.6.norm.weight', 'module.waffleiron.spatial_mix.6.norm.bias', 'module.waffleiron.spatial_mix.6.ffn.0.weight', 'module.waffleiron.spatial_mix.6.ffn.0.bias', 'module.waffleiron.spatial_mix.6.ffn.2.weight', 'module.waffleiron.spatial_mix.6.ffn.2.bias', 'module.waffleiron.spatial_mix.7.scale.weight', 'module.waffleiron.spatial_mix.7.norm.weight', 'module.waffleiron.spatial_mix.7.norm.bias', 'module.waffleiron.spatial_mix.7.ffn.0.weight', 'module.waffleiron.spatial_mix.7.ffn.0.bias', 'module.waffleiron.spatial_mix.7.ffn.2.weight', 'module.waffleiron.spatial_mix.7.ffn.2.bias', 'module.waffleiron.spatial_mix.8.scale.weight', 'module.waffleiron.spatial_mix.8.norm.weight', 'module.waffleiron.spatial_mix.8.norm.bias', 'module.waffleiron.spatial_mix.8.ffn.0.weight', 'module.waffleiron.spatial_mix.8.ffn.0.bias', 'module.waffleiron.spatial_mix.8.ffn.2.weight', 'module.waffleiron.spatial_mix.8.ffn.2.bias', 'module.waffleiron.spatial_mix.9.scale.weight', 'module.waffleiron.spatial_mix.9.norm.weight', 'module.waffleiron.spatial_mix.9.norm.bias', 'module.waffleiron.spatial_mix.9.ffn.0.weight', 'module.waffleiron.spatial_mix.9.ffn.0.bias', 'module.waffleiron.spatial_mix.9.ffn.2.weight', 'module.waffleiron.spatial_mix.9.ffn.2.bias', 'module.waffleiron.spatial_mix.10.scale.weight', 'module.waffleiron.spatial_mix.10.norm.weight', 'module.waffleiron.spatial_mix.10.norm.bias', 'module.waffleiron.spatial_mix.10.ffn.0.weight', 'module.waffleiron.spatial_mix.10.ffn.0.bias', 'module.waffleiron.spatial_mix.10.ffn.2.weight', 'module.waffleiron.spatial_mix.10.ffn.2.bias', 'module.waffleiron.spatial_mix.11.scale.weight', 'module.waffleiron.spatial_mix.11.norm.weight', 'module.waffleiron.spatial_mix.11.norm.bias', 'module.waffleiron.spatial_mix.11.ffn.0.weight', 'module.waffleiron.spatial_mix.11.ffn.0.bias', 'module.waffleiron.spatial_mix.11.ffn.2.weight', 'module.waffleiron.spatial_mix.11.ffn.2.bias', 'module.waffleiron.spatial_mix.12.scale.weight', 'module.waffleiron.spatial_mix.12.norm.weight', 'module.waffleiron.spatial_mix.12.norm.bias', 'module.waffleiron.spatial_mix.12.ffn.0.weight', 'module.waffleiron.spatial_mix.12.ffn.0.bias', 'module.waffleiron.spatial_mix.12.ffn.2.weight', 'module.waffleiron.spatial_mix.12.ffn.2.bias', 'module.waffleiron.spatial_mix.13.scale.weight', 'module.waffleiron.spatial_mix.13.norm.weight', 'module.waffleiron.spatial_mix.13.norm.bias', 'module.waffleiron.spatial_mix.13.ffn.0.weight', 'module.waffleiron.spatial_mix.13.ffn.0.bias', 'module.waffleiron.spatial_mix.13.ffn.2.weight', 'module.waffleiron.spatial_mix.13.ffn.2.bias', 'module.waffleiron.spatial_mix.14.scale.weight', 'module.waffleiron.spatial_mix.14.norm.weight', 'module.waffleiron.spatial_mix.14.norm.bias', 'module.waffleiron.spatial_mix.14.ffn.0.weight', 'module.waffleiron.spatial_mix.14.ffn.0.bias', 'module.waffleiron.spatial_mix.14.ffn.2.weight', 'module.waffleiron.spatial_mix.14.ffn.2.bias', 'module.waffleiron.spatial_mix.15.scale.weight', 'module.waffleiron.spatial_mix.15.norm.weight', 'module.waffleiron.spatial_mix.15.norm.bias', 'module.waffleiron.spatial_mix.15.ffn.0.weight', 'module.waffleiron.spatial_mix.15.ffn.0.bias', 'module.waffleiron.spatial_mix.15.ffn.2.weight', 'module.waffleiron.spatial_mix.15.ffn.2.bias', 'module.waffleiron.spatial_mix.16.scale.weight', 'module.waffleiron.spatial_mix.16.norm.weight', 'module.waffleiron.spatial_mix.16.norm.bias', 'module.waffleiron.spatial_mix.16.ffn.0.weight', 'module.waffleiron.spatial_mix.16.ffn.0.bias', 'module.waffleiron.spatial_mix.16.ffn.2.weight', 'module.waffleiron.spatial_mix.16.ffn.2.bias', 'module.waffleiron.spatial_mix.17.scale.weight', 'module.waffleiron.spatial_mix.17.norm.weight', 'module.waffleiron.spatial_mix.17.norm.bias', 'module.waffleiron.spatial_mix.17.ffn.0.weight', 'module.waffleiron.spatial_mix.17.ffn.0.bias', 'module.waffleiron.spatial_mix.17.ffn.2.weight', 'module.waffleiron.spatial_mix.17.ffn.2.bias', 'module.waffleiron.spatial_mix.18.scale.weight', 'module.waffleiron.spatial_mix.18.norm.weight', 'module.waffleiron.spatial_mix.18.norm.bias', 'module.waffleiron.spatial_mix.18.ffn.0.weight', 'module.waffleiron.spatial_mix.18.ffn.0.bias', 'module.waffleiron.spatial_mix.18.ffn.2.weight', 'module.waffleiron.spatial_mix.18.ffn.2.bias', 'module.waffleiron.spatial_mix.19.scale.weight', 'module.waffleiron.spatial_mix.19.norm.weight', 'module.waffleiron.spatial_mix.19.norm.bias', 'module.waffleiron.spatial_mix.19.ffn.0.weight', 'module.waffleiron.spatial_mix.19.ffn.0.bias', 'module.waffleiron.spatial_mix.19.ffn.2.weight', 'module.waffleiron.spatial_mix.19.ffn.2.bias', 'module.waffleiron.spatial_mix.20.scale.weight', 'module.waffleiron.spatial_mix.20.norm.weight', 'module.waffleiron.spatial_mix.20.norm.bias', 'module.waffleiron.spatial_mix.20.ffn.0.weight', 'module.waffleiron.spatial_mix.20.ffn.0.bias', 'module.waffleiron.spatial_mix.20.ffn.2.weight', 'module.waffleiron.spatial_mix.20.ffn.2.bias', 'module.waffleiron.spatial_mix.21.scale.weight', 'module.waffleiron.spatial_mix.21.norm.weight', 'module.waffleiron.spatial_mix.21.norm.bias', 'module.waffleiron.spatial_mix.21.ffn.0.weight', 'module.waffleiron.spatial_mix.21.ffn.0.bias', 'module.waffleiron.spatial_mix.21.ffn.2.weight', 'module.waffleiron.spatial_mix.21.ffn.2.bias', 'module.waffleiron.spatial_mix.22.scale.weight', 'module.waffleiron.spatial_mix.22.norm.weight', 'module.waffleiron.spatial_mix.22.norm.bias', 'module.waffleiron.spatial_mix.22.ffn.0.weight', 'module.waffleiron.spatial_mix.22.ffn.0.bias', 'module.waffleiron.spatial_mix.22.ffn.2.weight', 'module.waffleiron.spatial_mix.22.ffn.2.bias', 'module.waffleiron.spatial_mix.23.scale.weight', 'module.waffleiron.spatial_mix.23.norm.weight', 'module.waffleiron.spatial_mix.23.norm.bias', 'module.waffleiron.spatial_mix.23.ffn.0.weight', 'module.waffleiron.spatial_mix.23.ffn.0.bias', 'module.waffleiron.spatial_mix.23.ffn.2.weight', 'module.waffleiron.spatial_mix.23.ffn.2.bias', 'module.waffleiron.spatial_mix.24.scale.weight', 'module.waffleiron.spatial_mix.24.norm.weight', 'module.waffleiron.spatial_mix.24.norm.bias', 'module.waffleiron.spatial_mix.24.ffn.0.weight', 'module.waffleiron.spatial_mix.24.ffn.0.bias', 'module.waffleiron.spatial_mix.24.ffn.2.weight', 'module.waffleiron.spatial_mix.24.ffn.2.bias', 'module.waffleiron.spatial_mix.25.scale.weight', 'module.waffleiron.spatial_mix.25.norm.weight', 'module.waffleiron.spatial_mix.25.norm.bias', 'module.waffleiron.spatial_mix.25.ffn.0.weight', 'module.waffleiron.spatial_mix.25.ffn.0.bias', 'module.waffleiron.spatial_mix.25.ffn.2.weight', 'module.waffleiron.spatial_mix.25.ffn.2.bias', 'module.waffleiron.spatial_mix.26.scale.weight', 'module.waffleiron.spatial_mix.26.norm.weight', 'module.waffleiron.spatial_mix.26.norm.bias', 'module.waffleiron.spatial_mix.26.ffn.0.weight', 'module.waffleiron.spatial_mix.26.ffn.0.bias', 'module.waffleiron.spatial_mix.26.ffn.2.weight', 'module.waffleiron.spatial_mix.26.ffn.2.bias', 'module.waffleiron.spatial_mix.27.scale.weight', 'module.waffleiron.spatial_mix.27.norm.weight', 'module.waffleiron.spatial_mix.27.norm.bias', 'module.waffleiron.spatial_mix.27.ffn.0.weight', 'module.waffleiron.spatial_mix.27.ffn.0.bias', 'module.waffleiron.spatial_mix.27.ffn.2.weight', 'module.waffleiron.spatial_mix.27.ffn.2.bias', 'module.waffleiron.spatial_mix.28.scale.weight', 'module.waffleiron.spatial_mix.28.norm.weight', 'module.waffleiron.spatial_mix.28.norm.bias', 'module.waffleiron.spatial_mix.28.ffn.0.weight', 'module.waffleiron.spatial_mix.28.ffn.0.bias', 'module.waffleiron.spatial_mix.28.ffn.2.weight', 'module.waffleiron.spatial_mix.28.ffn.2.bias', 'module.waffleiron.spatial_mix.29.scale.weight', 'module.waffleiron.spatial_mix.29.norm.weight', 'module.waffleiron.spatial_mix.29.norm.bias', 'module.waffleiron.spatial_mix.29.ffn.0.weight', 'module.waffleiron.spatial_mix.29.ffn.0.bias', 'module.waffleiron.spatial_mix.29.ffn.2.weight', 'module.waffleiron.spatial_mix.29.ffn.2.bias', 'module.waffleiron.spatial_mix.30.scale.weight', 'module.waffleiron.spatial_mix.30.norm.weight', 'module.waffleiron.spatial_mix.30.norm.bias', 'module.waffleiron.spatial_mix.30.ffn.0.weight', 'module.waffleiron.spatial_mix.30.ffn.0.bias', 'module.waffleiron.spatial_mix.30.ffn.2.weight', 'module.waffleiron.spatial_mix.30.ffn.2.bias', 'module.waffleiron.spatial_mix.31.scale.weight', 'module.waffleiron.spatial_mix.31.norm.weight', 'module.waffleiron.spatial_mix.31.norm.bias', 'module.waffleiron.spatial_mix.31.ffn.0.weight', 'module.waffleiron.spatial_mix.31.ffn.0.bias', 'module.waffleiron.spatial_mix.31.ffn.2.weight', 'module.waffleiron.spatial_mix.31.ffn.2.bias', 'module.waffleiron.spatial_mix.32.scale.weight', 'module.waffleiron.spatial_mix.32.norm.weight', 'module.waffleiron.spatial_mix.32.norm.bias', 'module.waffleiron.spatial_mix.32.ffn.0.weight', 'module.waffleiron.spatial_mix.32.ffn.0.bias', 'module.waffleiron.spatial_mix.32.ffn.2.weight', 'module.waffleiron.spatial_mix.32.ffn.2.bias', 'module.waffleiron.spatial_mix.33.scale.weight', 'module.waffleiron.spatial_mix.33.norm.weight', 'module.waffleiron.spatial_mix.33.norm.bias', 'module.waffleiron.spatial_mix.33.ffn.0.weight', 'module.waffleiron.spatial_mix.33.ffn.0.bias', 'module.waffleiron.spatial_mix.33.ffn.2.weight', 'module.waffleiron.spatial_mix.33.ffn.2.bias', 'module.waffleiron.spatial_mix.34.scale.weight', 'module.waffleiron.spatial_mix.34.norm.weight', 'module.waffleiron.spatial_mix.34.norm.bias', 'module.waffleiron.spatial_mix.34.ffn.0.weight', 'module.waffleiron.spatial_mix.34.ffn.0.bias', 'module.waffleiron.spatial_mix.34.ffn.2.weight', 'module.waffleiron.spatial_mix.34.ffn.2.bias', 'module.waffleiron.spatial_mix.35.scale.weight', 'module.waffleiron.spatial_mix.35.norm.weight', 'module.waffleiron.spatial_mix.35.norm.bias', 'module.waffleiron.spatial_mix.35.ffn.0.weight', 'module.waffleiron.spatial_mix.35.ffn.0.bias', 'module.waffleiron.spatial_mix.35.ffn.2.weight', 'module.waffleiron.spatial_mix.35.ffn.2.bias', 'module.waffleiron.spatial_mix.36.scale.weight', 'module.waffleiron.spatial_mix.36.norm.weight', 'module.waffleiron.spatial_mix.36.norm.bias', 'module.waffleiron.spatial_mix.36.ffn.0.weight', 'module.waffleiron.spatial_mix.36.ffn.0.bias', 'module.waffleiron.spatial_mix.36.ffn.2.weight', 'module.waffleiron.spatial_mix.36.ffn.2.bias', 'module.waffleiron.spatial_mix.37.scale.weight', 'module.waffleiron.spatial_mix.37.norm.weight', 'module.waffleiron.spatial_mix.37.norm.bias', 'module.waffleiron.spatial_mix.37.ffn.0.weight', 'module.waffleiron.spatial_mix.37.ffn.0.bias', 'module.waffleiron.spatial_mix.37.ffn.2.weight', 'module.waffleiron.spatial_mix.37.ffn.2.bias', 'module.waffleiron.spatial_mix.38.scale.weight', 'module.waffleiron.spatial_mix.38.norm.weight', 'module.waffleiron.spatial_mix.38.norm.bias', 'module.waffleiron.spatial_mix.38.ffn.0.weight', 'module.waffleiron.spatial_mix.38.ffn.0.bias', 'module.waffleiron.spatial_mix.38.ffn.2.weight', 'module.waffleiron.spatial_mix.38.ffn.2.bias', 'module.waffleiron.spatial_mix.39.scale.weight', 'module.waffleiron.spatial_mix.39.norm.weight', 'module.waffleiron.spatial_mix.39.norm.bias', 'module.waffleiron.spatial_mix.39.ffn.0.weight', 'module.waffleiron.spatial_mix.39.ffn.0.bias', 'module.waffleiron.spatial_mix.39.ffn.2.weight', 'module.waffleiron.spatial_mix.39.ffn.2.bias', 'module.waffleiron.spatial_mix.40.scale.weight', 'module.waffleiron.spatial_mix.40.norm.weight', 'module.waffleiron.spatial_mix.40.norm.bias', 'module.waffleiron.spatial_mix.40.ffn.0.weight', 'module.waffleiron.spatial_mix.40.ffn.0.bias', 'module.waffleiron.spatial_mix.40.ffn.2.weight', 'module.waffleiron.spatial_mix.40.ffn.2.bias', 'module.waffleiron.spatial_mix.41.scale.weight', 'module.waffleiron.spatial_mix.41.norm.weight', 'module.waffleiron.spatial_mix.41.norm.bias', 'module.waffleiron.spatial_mix.41.ffn.0.weight', 'module.waffleiron.spatial_mix.41.ffn.0.bias', 'module.waffleiron.spatial_mix.41.ffn.2.weight', 'module.waffleiron.spatial_mix.41.ffn.2.bias', 'module.waffleiron.spatial_mix.42.scale.weight', 'module.waffleiron.spatial_mix.42.norm.weight', 'module.waffleiron.spatial_mix.42.norm.bias', 'module.waffleiron.spatial_mix.42.ffn.0.weight', 'module.waffleiron.spatial_mix.42.ffn.0.bias', 'module.waffleiron.spatial_mix.42.ffn.2.weight', 'module.waffleiron.spatial_mix.42.ffn.2.bias', 'module.waffleiron.spatial_mix.43.scale.weight', 'module.waffleiron.spatial_mix.43.norm.weight', 'module.waffleiron.spatial_mix.43.norm.bias', 'module.waffleiron.spatial_mix.43.ffn.0.weight', 'module.waffleiron.spatial_mix.43.ffn.0.bias', 'module.waffleiron.spatial_mix.43.ffn.2.weight', 'module.waffleiron.spatial_mix.43.ffn.2.bias', 'module.waffleiron.spatial_mix.44.scale.weight', 'module.waffleiron.spatial_mix.44.norm.weight', 'module.waffleiron.spatial_mix.44.norm.bias', 'module.waffleiron.spatial_mix.44.ffn.0.weight', 'module.waffleiron.spatial_mix.44.ffn.0.bias', 'module.waffleiron.spatial_mix.44.ffn.2.weight', 'module.waffleiron.spatial_mix.44.ffn.2.bias', 'module.waffleiron.spatial_mix.45.scale.weight', 'module.waffleiron.spatial_mix.45.norm.weight', 'module.waffleiron.spatial_mix.45.norm.bias', 'module.waffleiron.spatial_mix.45.ffn.0.weight', 'module.waffleiron.spatial_mix.45.ffn.0.bias', 'module.waffleiron.spatial_mix.45.ffn.2.weight', 'module.waffleiron.spatial_mix.45.ffn.2.bias', 'module.waffleiron.spatial_mix.46.scale.weight', 'module.waffleiron.spatial_mix.46.norm.weight', 'module.waffleiron.spatial_mix.46.norm.bias', 'module.waffleiron.spatial_mix.46.ffn.0.weight', 'module.waffleiron.spatial_mix.46.ffn.0.bias', 'module.waffleiron.spatial_mix.46.ffn.2.weight', 'module.waffleiron.spatial_mix.46.ffn.2.bias', 'module.waffleiron.spatial_mix.47.scale.weight', 'module.waffleiron.spatial_mix.47.norm.weight', 'module.waffleiron.spatial_mix.47.norm.bias', 'module.waffleiron.spatial_mix.47.ffn.0.weight', 'module.waffleiron.spatial_mix.47.ffn.0.bias', 'module.waffleiron.spatial_mix.47.ffn.2.weight', 'module.waffleiron.spatial_mix.47.ffn.2.bias', 'module.classif.0.weight', 'module.classif.0.bias', 'module.classif.0.running_mean', 'module.classif.0.running_var', 'module.classif.0.num_batches_tracked', 'module.classif.1.weight', 'module.classif.1.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c587871",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ckpt = {}\n",
    "for k in ckpt.keys():\n",
    "    if k.startswith(\"module\"):\n",
    "        if k.startswith(\"module.classif.0\"):\n",
    "            continue\n",
    "        elif k.startswith(\"module.classif.1\"):\n",
    "            new_ckpt[\"classif\" + k[len(\"module.classif.1\") :]] = ckpt[k]\n",
    "        else:\n",
    "            new_ckpt[k[len(\"module.\") :]] = ckpt[k]\n",
    "    else:\n",
    "        new_ckpt[k] = ckpt[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a10e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ckpt.get(\"classif.weight\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ca00085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(new_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84e7d8",
   "metadata": {},
   "source": [
    "## Model loaded --> Test features somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f791bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from auxiliary.process_data.nuscenes.nuscenes_dataset import DatasetTrainVal\n",
    "\n",
    "print(\"Creating dataloader...\", flush=True)\n",
    "\n",
    "target = '/root/main/dataset/processed'\n",
    "\n",
    "filelist_train = [os.path.join(target, 'train_pointclouds', fname) for fname in os.listdir(os.path.join(target, 'train_pointclouds')) if os.path.splitext(fname)[1]==\".npy\"]\n",
    "filelist_train.sort()\n",
    "filelist_val = filelist_train[:3]\n",
    "filelist_train = filelist_train[3:]\n",
    "\n",
    "ds = DatasetTrainVal(filelist_train, os.path.join(target, 'train_pointclouds'),\n",
    "                            training=True,\n",
    "                            npoints=2000,\n",
    "                            iteration_number=(2*10)*10,\n",
    "                            jitter=0.2)\n",
    "train_loader = torch.utils.data.DataLoader(ds, batch_size=1, shuffle=False, # Change batch_size\n",
    "                                    num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2884a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in train_loader:\n",
    "    print(torch.bincount(t['target'][0]))\n",
    "    x = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca8d1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData, PlyElement\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "train_filenames = [\"Lille1_1.ply\",  \"Lille1_2.ply\",  \"Lille2.ply\",  \"Paris.ply\",]\n",
    "destdir = '/root/main/dataset/processed/'\n",
    "rootdir = '/root/main/dataset/'\n",
    "\n",
    "filenames = train_filenames\n",
    "save_dir = os.path.join(destdir,\"train_pointclouds\")\n",
    "pts_all = {}\n",
    "for filename in filenames:\n",
    "    fname = os.path.join(rootdir, \"training_10_classes\", filename)\n",
    "    plydata = PlyData.read(fname)\n",
    "    x = plydata[\"vertex\"].data[\"x\"].astype(np.float32)\n",
    "    y = plydata[\"vertex\"].data[\"y\"].astype(np.float32)\n",
    "    z = plydata[\"vertex\"].data[\"z\"].astype(np.float32)\n",
    "    reflectance = plydata[\"vertex\"].data[\"reflectance\"].astype(np.float32)\n",
    "    label = plydata[\"vertex\"].data[\"class\"].astype(np.float32)\n",
    "    pts = np.concatenate([\n",
    "        np.expand_dims(x,1),\n",
    "        np.expand_dims(y,1),\n",
    "        np.expand_dims(z,1),\n",
    "        np.expand_dims(reflectance,1),\n",
    "        np.expand_dims(label,1),\n",
    "    ], axis=1).astype(np.float32)\n",
    "    pts_all[filename] = pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dfc59a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  83.03686 ,   83.05253 ,   83.117584, ..., -386.54715 ,\n",
       "       -386.5629  , -386.97958 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_all[\"Lille1_1.ply\"][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a6462b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-360.1785\n",
      "67.185555\n",
      "-412.13937\n",
      "101.893524\n",
      "32.78496\n",
      "66.74454\n"
     ]
    }
   ],
   "source": [
    "print(min(pts_all[\"Lille1_1.ply\"][:,0]))\n",
    "print(max(pts_all[\"Lille1_1.ply\"][:,0]))\n",
    "print(min(pts_all[\"Lille1_1.ply\"][:,1]))\n",
    "print(max(pts_all[\"Lille1_1.ply\"][:,1]))\n",
    "print(min(pts_all[\"Lille1_1.ply\"][:,2]))\n",
    "print(max(pts_all[\"Lille1_1.ply\"][:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4331e8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.701644699999996"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(101.893524 - (-412.13937))/20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e96dcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20 * 25 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01441ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.705505\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(pts_all[\"Lille1_1.ply\"][:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6416d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.756725\n"
     ]
    }
   ],
   "source": [
    "print(np.std(pts_all[\"Lille1_1.ply\"][:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfb4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "pc_here = torch.from_numpy(pts_all[\"Lille1_1.ply\"]).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelize_pointcloud(points, voxel_size):\n",
    "    \"\"\"\n",
    "    Voxelizes a point cloud.\n",
    "\n",
    "    Args:\n",
    "        points (np.ndarray): The point cloud as an Nx3 array of XYZ coordinates.\n",
    "        voxel_size (float): The size of the voxels (uniform along all axes).\n",
    "        \n",
    "    Returns:\n",
    "        voxel_indices (np.ndarray): The voxel indices for each point.\n",
    "        voxel_grid (dict): A dictionary where keys are voxel indices (tuples) and values are points in that voxel.\n",
    "    \"\"\"\n",
    "    # Normalize points by voxel size\n",
    "    voxel_indices = np.floor(points[:,:3] / voxel_size).astype(np.int32)\n",
    "    \n",
    "    # Create a dictionary to store points in each voxel\n",
    "    voxel_grid = {}\n",
    "    \n",
    "    for idx, voxel in tqdm(enumerate(voxel_indices)):\n",
    "        voxel_key = tuple(voxel)  # Use tuple to make it hashable for the dictionary\n",
    "        if voxel_key not in voxel_grid:\n",
    "            voxel_grid[voxel_key] = []\n",
    "        voxel_grid[voxel_key].append(points[idx])\n",
    "    \n",
    "    # Convert lists to arrays\n",
    "    for key in voxel_grid:\n",
    "        voxel_grid[key] = np.array(voxel_grid[key])\n",
    "    \n",
    "    return voxel_indices, voxel_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9efe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "#point_cloud = np.random.rand(1000, 3) * 100  # 1000 points in a 100x100x100 space\n",
    "voxel_size = 20.0  # Voxel size of 5 units\n",
    "\n",
    "# Voxelize the point cloud\n",
    "voxel_indices, voxel_grid = voxelize_pointcloud(pts_all[\"Lille1_1.ply\"], voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eac2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some results\n",
    "print(\"Voxel indices:\\n\", voxel_indices[900])  # Show first 10 voxel indices\n",
    "print(\"\\nNumber of unique voxels:\", len(voxel_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(voxel_grid.keys()):\n",
    "    print(\"\\nPoints in a specific voxel:\", len(voxel_grid[i]))\n",
    "    if len(voxel_grid[i]) < 100:\n",
    "        voxel_grid.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(voxel_grid.keys()):\n",
    "    print(\"\\nPoints in a specific voxel:\", len(voxel_grid[i]))\n",
    "    voxel_grid[i][:,4] = voxel_grid[i][:,4] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(voxel_grid.keys()):\n",
    "    print(voxel_grid[i][:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f2c3d",
   "metadata": {},
   "source": [
    "## Model Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c4ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(\"cuda:0\")\n",
    "model = model.cuda(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e309a941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Segmenter(\n",
       "  (embed): Embedding(\n",
       "    (norm): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv1d(5, 768, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Sequential(\n",
       "      (0): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Conv2d(5, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (final): Conv1d(1536, 768, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (waffleiron): WaffleIron(\n",
       "    (channel_mix): ModuleList(\n",
       "      (0): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (1): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (2): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (3): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (4): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (5): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (6): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (7): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (8): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (9): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (10): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (11): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (12): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (13): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (14): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (15): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (16): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (17): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (18): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (19): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (20): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (21): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (22): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (23): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (24): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (25): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (26): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (27): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (28): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (29): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (30): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (31): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (32): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (33): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (34): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (35): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (36): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (37): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (38): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (39): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (40): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (41): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (42): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (43): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (44): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (45): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (46): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (47): ChannelMix(\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "    (spatial_mix): ModuleList(\n",
       "      (0): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (1): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (2): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (3): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (4): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (5): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (6): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (7): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (8): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (9): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (10): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (11): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (12): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (13): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (14): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (15): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (16): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (17): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (18): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (19): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (20): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (21): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (22): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (23): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (24): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (25): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (26): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (27): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (28): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (29): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (30): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (31): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (32): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (33): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (34): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (35): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (36): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (37): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (38): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (39): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (40): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (41): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (42): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (43): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (44): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (45): SpatialMix(\n",
       "        (grid): [256, 256]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (46): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "      (47): SpatialMix(\n",
       "        (grid): [256, 32]\n",
       "        (norm): myLayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "        )\n",
       "        (scale): Conv1d(768, 768, kernel_size=(1,), stride=(1,), groups=768, bias=False)\n",
       "        (drop_path): DropPath(prob=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classif): Conv1d(768, 16, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d10d39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import utils.transforms as tr\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "import os\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "class PCDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rootdir=None,\n",
    "        phase=\"train\",\n",
    "        input_feat=\"intensity\",\n",
    "        voxel_size=0.1,\n",
    "        train_augmentations=None,\n",
    "        dim_proj=[\n",
    "            0,\n",
    "        ],\n",
    "        grids_shape=[(256, 256)],\n",
    "        fov_xyz=(\n",
    "            (-1.0, -1.0, -1.0),\n",
    "            (1.0, 1.0, 1.0),\n",
    "        ),\n",
    "        num_neighbors=16,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Dataset split\n",
    "        self.phase = phase\n",
    "        assert self.phase in [\"train\", \"val\", \"trainval\", \"test\"]\n",
    "\n",
    "        # Root directory of dataset\n",
    "        self.rootdir = rootdir\n",
    "\n",
    "        # Input features to compute for each point\n",
    "        self.input_feat = input_feat\n",
    "\n",
    "        # Downsample input point cloud by small voxelization\n",
    "        self.downsample = tr.Voxelize(\n",
    "            dims=(0, 1, 2),\n",
    "            voxel_size=voxel_size,\n",
    "            random=(self.phase == \"train\" or self.phase == \"trainval\"),\n",
    "        )\n",
    "\n",
    "        # Field of view\n",
    "        assert len(fov_xyz[0]) == len(\n",
    "            fov_xyz[1]\n",
    "        ), \"Min and Max FOV must have the same length.\"\n",
    "        for i, (min, max) in enumerate(zip(*fov_xyz)):\n",
    "            assert (\n",
    "                min < max\n",
    "            ), f\"Field of view: min ({min}) < max ({max}) is expected on dimension {i}.\"\n",
    "        self.fov_xyz = np.concatenate([np.array(f)[None] for f in fov_xyz], axis=0)\n",
    "        self.crop_to_fov = tr.Crop(dims=(0, 1, 2), fov=fov_xyz)\n",
    "\n",
    "        # Grid shape for projection in 2D\n",
    "        assert len(grids_shape) == len(dim_proj)\n",
    "        self.dim_proj = dim_proj\n",
    "        self.grids_shape = [np.array(g) for g in grids_shape]\n",
    "        self.lut_axis_plane = {0: (1, 2), 1: (0, 2), 2: (0, 1)}\n",
    "\n",
    "        # Number of neighbors for embedding layer\n",
    "        assert num_neighbors > 0\n",
    "        self.num_neighbors = num_neighbors\n",
    "\n",
    "        # Train time augmentations\n",
    "        if train_augmentations is not None:\n",
    "            assert self.phase in [\"train\", \"trainval\"]\n",
    "        self.train_augmentations = train_augmentations\n",
    "        \n",
    "        self.list_frames = [\"Lille1_1.ply\"] # ,  \"Lille1_2.ply\",  \"Lille2.ply\",  \"Paris.ply\",\n",
    "        self.mean_int = 18.705505\n",
    "        self.std_int = 23.756725\n",
    "\n",
    "    def get_occupied_2d_cells(self, pc):\n",
    "        \"\"\"Return mapping between 3D point and corresponding 2D cell\"\"\"\n",
    "        cell_ind = []\n",
    "        for dim, grid in zip(self.dim_proj, self.grids_shape):\n",
    "            # Get plane of which to project\n",
    "            dims = self.lut_axis_plane[dim]\n",
    "            # Compute grid resolution\n",
    "            res = (self.fov_xyz[1, dims] - self.fov_xyz[0, dims]) / grid[None]\n",
    "            # Shift and quantize point cloud\n",
    "            pc_quant = ((pc[:, dims] - self.fov_xyz[0, dims]) / res).astype(\"int\")\n",
    "            # Check that the point cloud fits on the grid\n",
    "            min, max = pc_quant.min(0), pc_quant.max(0)\n",
    "            assert min[0] >= 0 and min[1] >= 0, print(\n",
    "                \"Some points are outside the FOV:\", pc[:, :3].min(0), self.fov_xyz\n",
    "            )\n",
    "            assert max[0] < grid[0] and max[1] < grid[1], print(\n",
    "                \"Some points are outside the FOV:\", pc[:, :3].min(0), self.fov_xyz\n",
    "            )\n",
    "            # Transform quantized coordinates to cell indices for projection on 2D plane\n",
    "            temp = pc_quant[:, 0] * grid[1] + pc_quant[:, 1]\n",
    "            cell_ind.append(temp[None])\n",
    "        return np.vstack(cell_ind)\n",
    "\n",
    "    def prepare_input_features(self, pc_orig):\n",
    "        # Concatenate desired input features to coordinates\n",
    "        pc = [pc_orig[:, :3]]  # Initialize with coordinates\n",
    "        for type in self.input_feat:\n",
    "            if type == \"intensity\":\n",
    "                intensity = pc_orig[:, 3:]\n",
    "                intensity = (intensity - self.mean_int) / self.std_int\n",
    "                pc.append(intensity)\n",
    "            elif type == \"height\":\n",
    "                pc.append(pc_orig[:, 2:3])\n",
    "            elif type == \"radius\":\n",
    "                r_xyz = np.linalg.norm(pc_orig[:, :3], axis=1, keepdims=True)\n",
    "                pc.append(r_xyz)\n",
    "            elif type == \"xyz\":\n",
    "                xyz = pc_orig[:, :3]\n",
    "                pc.append(xyz)\n",
    "            elif type == \"constant\":\n",
    "                pc.append(np.ones((pc_orig.shape[0], 1)))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown feature: {type}\")\n",
    "        return np.concatenate(pc, 1)\n",
    "\n",
    "    def load_pc(self, index):\n",
    "        fname = os.path.join(self.rootdir, \"training_10_classes\", self.list_frames[index])\n",
    "        print(\"Loading\")\n",
    "        plydata = PlyData.read(fname)\n",
    "        x = plydata[\"vertex\"].data[\"x\"].astype(np.float32)\n",
    "        y = plydata[\"vertex\"].data[\"y\"].astype(np.float32)\n",
    "        z = plydata[\"vertex\"].data[\"z\"].astype(np.float32)\n",
    "        z = z - 36\n",
    "        reflectance = plydata[\"vertex\"].data[\"reflectance\"].astype(np.float32)\n",
    "        #print(x.shape[0])\n",
    "        feats = np.zeros((x.shape[0], 1))\n",
    "        label = plydata[\"vertex\"].data[\"class\"].astype(np.float32)\n",
    "        #label = label-1\n",
    "        pts = np.concatenate([\n",
    "            np.expand_dims(x,1),\n",
    "            np.expand_dims(y,1),\n",
    "            np.expand_dims(z,1),\n",
    "            np.expand_dims(reflectance,1),\n",
    "            feats,\n",
    "        ], axis=1).astype(np.float32)\n",
    "        print(\"Finished\")\n",
    "        \n",
    "        return pts, np.expand_dims(label,1), self.list_frames[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_frames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load original point cloud\n",
    "        pc_orig, labels_orig, filename = self.load_pc(index)\n",
    "\n",
    "        # Prepare input feature\n",
    "        pc_orig = self.prepare_input_features(pc_orig)\n",
    "\n",
    "        # Voxelization\n",
    "        pc, labels = self.downsample(pc_orig, labels_orig)\n",
    "\n",
    "        # Augment data\n",
    "        if self.train_augmentations is not None:\n",
    "            pc, labels = self.train_augmentations(pc, labels)\n",
    "\n",
    "        # Crop to fov\n",
    "        pc, labels = self.crop_to_fov(pc, labels)\n",
    "\n",
    "        # For each point, get index of corresponding 2D cells on projected grid\n",
    "        cell_ind = self.get_occupied_2d_cells(pc)\n",
    "\n",
    "        # Get neighbors for point embedding layer providing tokens to waffleiron backbone\n",
    "        kdtree = KDTree(pc[:, :3])\n",
    "        assert pc.shape[0] > self.num_neighbors\n",
    "        dist, neighbors_emb = kdtree.query(pc[:, :3], k=self.num_neighbors + 1)\n",
    "\n",
    "        # Nearest neighbor interpolation to undo cropping & voxelisation at validation time\n",
    "        if self.phase in [\"train\", \"trainval\"]:\n",
    "            upsample = np.arange(pc.shape[0])\n",
    "        else:\n",
    "            _, upsample = kdtree.query(pc_orig[:, :3], k=1)\n",
    "\n",
    "        # Output to return\n",
    "        out = (\n",
    "            # Point features\n",
    "            pc[:, 3:].T[None],\n",
    "            # Point labels of original entire point cloud\n",
    "            labels if self.phase in [\"train\", \"trainval\"] else labels_orig,\n",
    "            # Projection 2D -> 3D: index of 2D cells for each point\n",
    "            cell_ind[None],\n",
    "            # Neighborhood for point embedding layer, which provides tokens to waffleiron backbone\n",
    "            neighbors_emb.T[None],\n",
    "            # For interpolation from voxelized & cropped point cloud to original point cloud\n",
    "            upsample,\n",
    "            # Filename of original point cloud\n",
    "            filename,\n",
    "        )\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "337afe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, num_points=None):\n",
    "        self.num_points = num_points\n",
    "        assert num_points is None or num_points > 0\n",
    "\n",
    "    def __call__(self, list_data):\n",
    "\n",
    "        # Extract all data\n",
    "        list_of_data = (list(data) for data in zip(*list_data))\n",
    "        feat, label_orig, cell_ind, neighbors_emb, upsample, filename = list_of_data\n",
    "\n",
    "        # Zero-pad point clouds\n",
    "        Nmax = np.max([f.shape[-1] for f in feat])\n",
    "        if self.num_points is not None:\n",
    "            assert Nmax <= self.num_points\n",
    "        occupied_cells = []\n",
    "        for i in range(len(feat)):\n",
    "            feat[i], neighbors_emb[i], cell_ind[i], temp = zero_pad(\n",
    "                feat[i],\n",
    "                neighbors_emb[i],\n",
    "                cell_ind[i],\n",
    "                Nmax if self.num_points is None else self.num_points,\n",
    "            )\n",
    "            occupied_cells.append(temp)\n",
    "\n",
    "        # Concatenate along batch dimension\n",
    "        feat = torch.from_numpy(np.vstack(feat)).float()  # B x C x Nmax\n",
    "        neighbors_emb = torch.from_numpy(np.vstack(neighbors_emb)).long()  # B x Nmax\n",
    "        cell_ind = torch.from_numpy(\n",
    "            np.vstack(cell_ind)\n",
    "        ).long()  # B x nb_2d_cells x Nmax\n",
    "        occupied_cells = torch.from_numpy(np.vstack(occupied_cells)).float()  # B x Nmax\n",
    "        labels_orig = torch.from_numpy(np.hstack(label_orig)).long()\n",
    "        upsample = [torch.from_numpy(u) for u in upsample]\n",
    "\n",
    "        # Prepare output variables\n",
    "        out = {\n",
    "            \"feat\": feat,\n",
    "            \"neighbors_emb\": neighbors_emb,\n",
    "            \"upsample\": upsample,\n",
    "            \"labels_orig\": labels_orig,\n",
    "            \"cell_ind\": cell_ind,\n",
    "            \"occupied_cells\": occupied_cells,\n",
    "            \"filename\": filename,\n",
    "        }\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e1814ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(feat, neighbors_emb, cell_ind, Nmax):\n",
    "    N = feat.shape[-1]\n",
    "    assert N <= Nmax\n",
    "    occupied_cells = np.ones((1, Nmax))\n",
    "    if N < Nmax:\n",
    "        # Zero-pad with null features\n",
    "        feat = np.concatenate((feat, np.zeros((1, feat.shape[1], Nmax - N))), axis=2)\n",
    "        # For zero-padded points, associate last zero-padded points as neighbor\n",
    "        neighbors_emb = np.concatenate(\n",
    "            (\n",
    "                neighbors_emb,\n",
    "                (Nmax - 1) * np.ones((1, neighbors_emb.shape[1], Nmax - N)),\n",
    "            ),\n",
    "            axis=2,\n",
    "        )\n",
    "        # Associate zero-padded points to first 2D cell...\n",
    "        cell_ind = np.concatenate(\n",
    "            (cell_ind, np.zeros((1, cell_ind.shape[1], Nmax - N))), axis=2\n",
    "        )\n",
    "        # ... and at the same time mark zero-padded points as unoccupied\n",
    "        occupied_cells[:, N:] = 0\n",
    "    return feat, neighbors_emb, cell_ind, occupied_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e3bad12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "        \"rootdir\": '/root/main/dataset/',\n",
    "        \"input_feat\": [\"xyz\", \"intensity\"],\n",
    "        \"voxel_size\": 0.2,\n",
    "        \"num_neighbors\": 32,\n",
    "        \"dim_proj\": [2, 1, 0],\n",
    "        \"grids_shape\": [[256, 256], [256, 32], [256, 32]],\n",
    "        \"fov_xyz\": [[-64, -64, -8], [64, 64, 8]], # Check here\n",
    "    }\n",
    "\n",
    "train_dataset = PCDataset(\n",
    "        phase=\"val\",\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c1dae585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=1,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=Collate(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7ce92bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "Finished\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 35.68 GiB (GPU 0; 21.98 GiB total capacity; 16.21 GiB already allocated; 4.90 GiB free; 16.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17709/1861210621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnet_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3DLabelProp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/HyperLiDAR/models/waffleiron/segmenter.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feats, cell_ind, occupied_cell, neighbors)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moccupied_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaffleiron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moccupied_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3DLabelProp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/HyperLiDAR/models/waffleiron/embedding.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, neighbors)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mneigh_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Size: (B x C x N) x K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mneigh_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Merge both embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3DLabelProp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3DLabelProp/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3DLabelProp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3DLabelProp/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3DLabelProp/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    459\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 460\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 35.68 GiB (GPU 0; 21.98 GiB total capacity; 16.21 GiB already allocated; 4.90 GiB free; 16.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for it, batch in enumerate(train_loader):\n",
    "    \n",
    "    if it == 0:\n",
    "\n",
    "        # Network inputs\n",
    "        #print(batch[\"upsample\"])\n",
    "        feat = batch[\"feat\"].cuda(0, non_blocking=True)\n",
    "        labels = batch[\"labels_orig\"].cuda(0, non_blocking=True)\n",
    "        batch[\"upsample\"] = [\n",
    "            up.cuda(0, non_blocking=True) for up in batch[\"upsample\"]\n",
    "        ]\n",
    "        cell_ind = batch[\"cell_ind\"].cuda(0, non_blocking=True)\n",
    "        occupied_cell = batch[\"occupied_cells\"].cuda(0, non_blocking=True)\n",
    "        neighbors_emb = batch[\"neighbors_emb\"].cuda(0, non_blocking=True)\n",
    "        net_inputs = (feat, cell_ind, occupied_cell, neighbors_emb)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(*net_inputs)\n",
    "        \n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6999c981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30033430, 1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ffb61411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([18394, 18394, 18394,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Voxels to points\n",
    "out_upsample = []\n",
    "for id_b, closest_point in enumerate(batch[\"upsample\"]):\n",
    "    print(id_b)\n",
    "    print(closest_point)\n",
    "    temp = out[id_b, :, closest_point]\n",
    "    out_upsample.append(temp.T)\n",
    "out_2 = torch.cat(out_upsample, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "25ee03ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 534.3236, -944.9010, -293.4177,  ...,   42.3363,  543.9377,\n",
       "            5.9916],\n",
       "        [ 534.3236, -944.9010, -293.4177,  ...,   42.3363,  543.9377,\n",
       "            5.9916],\n",
       "        [ 534.3236, -944.9010, -293.4177,  ...,   42.3363,  543.9377,\n",
       "            5.9916],\n",
       "        ...,\n",
       "        [-341.6503,  309.1094, -349.1234,  ...,  -97.4141,  715.1487,\n",
       "         -214.5612],\n",
       "        [-341.6503,  309.1094, -349.1234,  ...,  -97.4141,  715.1487,\n",
       "         -214.5612],\n",
       "        [-341.6503,  309.1094, -349.1234,  ...,  -97.4141,  715.1487,\n",
       "         -214.5612]], device='cuda:0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dc098256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30033430, 16])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "32f7a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    nb_class = out_2.shape[1]\n",
    "    pred_label = out_2.max(1)[1] + 1\n",
    "    labels = labels[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "80368336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30033430])\n",
      "torch.Size([30033430])\n"
     ]
    }
   ],
   "source": [
    "print(pred_label.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f283203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3a5cc781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8674f234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([       0,  1707795,   348723,    15179,  2423566,      183, 21135781,\n",
      "               0,     1933,    48110,   287413,  1236819,    35723,   110383,\n",
      "              65,  2675976,     5781], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.bincount(pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa3588",
   "metadata": {},
   "source": [
    "### Npm3D\n",
    "\n",
    "0 unclassified\n",
    "1 ground\n",
    "2 building\n",
    "3 pole - road sign - traffic light\n",
    "4 bollard - small pole\n",
    "5 trash can\n",
    "6 barrier\n",
    "7 pedestrian\n",
    "8 car\n",
    "9 natural - vegetation\n",
    "\n",
    "### Nuscenes\n",
    "\n",
    "0: 'noise'\n",
    "1: 'barrier'\n",
    "2: 'bicycle'\n",
    "3: 'bus'\n",
    "4: 'car'\n",
    "5: 'construction_vehicle'\n",
    "6: 'motorcycle'\n",
    "7: 'pedestrian'\n",
    "8: 'traffic_cone'\n",
    "9: 'trailer'\n",
    "10: 'truck'\n",
    "11: 'driveable_surface'\n",
    "12: 'other_flat'\n",
    "13: 'sidewalk'\n",
    "14: 'terrain'\n",
    "15: 'manmade'\n",
    "16: 'vegetation'\n",
    "\n",
    "0 - 0\n",
    "1 - 11 or 12 or 13 or 14\n",
    "2 - IGNORE\n",
    "3 - 8\n",
    "4 - IGNORE\n",
    "5 - IGNORE\n",
    "6 - 1\n",
    "7 - 7\n",
    "8 - 2 or 3 or 4 or 5 or 6 or 9 or 10\n",
    "9 - 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ed8ba850",
   "metadata": {},
   "outputs": [],
   "source": [
    "change = {1:6, 2:8, 3:8, 4:8, 5:8, 6:8, 7:7, 8:3, 9:9, 10:8, 11:1, 12:1, 13:1, 14:1, 15:2, 16:9} # 6:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fed8da73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 16/16 [00:00<00:00, 28208.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Create a lookup table (assuming tensor values are in a known range)\n",
    "max_key = max(change.keys())  # Find the largest key in the dictionary\n",
    "lookup_table = torch.zeros(max_key + 1, dtype=torch.long, device=torch.device('cuda'))  # Initialize the lookup table\n",
    "\n",
    "# Populate the lookup table with the dictionary values\n",
    "for key, value in tqdm(change.items()):\n",
    "    lookup_table[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a58d61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the lookup table to map the original tensor\n",
    "mapped_tensor = lookup_table[pred_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "920c353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2,  ..., 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "644996dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "43df19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of values you want to exclude\n",
    "from utils.metrics import overall_accuracy, fast_hist\n",
    "\n",
    "exclude_labels = torch.tensor([0, 2, 4, 5], device=torch.device('cuda'))\n",
    "\n",
    "where = ~torch.isin(labels, exclude_labels)\n",
    "confusion_matrix = fast_hist(\n",
    "    mapped_tensor[where], labels[where], 10\n",
    ") # pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "12fa974a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[       0,        0,        0,        0,        0,        0,        0,\n",
       "                0,        0,        0],\n",
       "        [       0, 14080488,   855137,        0,        0,        0,  1136648,\n",
       "                0,  1373940,    16655],\n",
       "        [       0,        0,        0,        0,        0,        0,        0,\n",
       "                0,        0,        0],\n",
       "        [       0,   127342,     9520,      116,        0,        0,     4185,\n",
       "                0,    24423,     1536],\n",
       "        [       0,        0,        0,        0,        0,        0,        0,\n",
       "                0,        0,        0],\n",
       "        [       0,        0,        0,        0,        0,        0,        0,\n",
       "                0,        0,        0],\n",
       "        [       0,   698518,    39489,        0,        0,        0,    16472,\n",
       "                0,   439399,    16650],\n",
       "        [       0,     9145,     1867,        0,        0,        0,     1641,\n",
       "                0,     3155,      482],\n",
       "        [       0,   850036,   194039,        0,        0,        0,   190141,\n",
       "                0,    50813,     6157],\n",
       "        [       0,  1437064,    38800,     1817,        0,        0,     5714,\n",
       "                0,   698382,     7044]], device='cuda:0')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "958e9a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Option 1: Use matplotlib to visualize the matrix as a heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(confusion_matrix.cpu(), cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()  # Add color bar to interpret the values\n",
    "plt.title('Confusion Matrix (fast_hist)')\n",
    "plt.savefig('fast_hist_heatmap.png')  # Save the heatmap as an image\n",
    "plt.show()  # Display the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "94bdbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3DLabelProp",
   "language": "python",
   "name": "3dlabelprop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
